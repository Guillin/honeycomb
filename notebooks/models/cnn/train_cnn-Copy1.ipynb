{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from barbar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f77d00e26f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history):\n",
    "    fig, axarr = plt.subplots(figsize=(12,6), ncols=2)\n",
    "    axarr[0].plot(range(0, len(history)), history['acc'], label='train score')\n",
    "    axarr[0].plot(range(0, len(history)), history['val_acc'], label='test score')\n",
    "    axarr[0].set_xlabel('Number of Epochs x 14', fontsize=18)\n",
    "    axarr[0].set_ylabel('Accuracy', fontsize=18)\n",
    "    axarr[0].set_ylim([0,1])\n",
    "    axarr[1].plot(range(0, len(history)), history['acc'], label='train score')\n",
    "    axarr[1].plot(range(0, len(history)), history['val_acc'], label='test score')\n",
    "    axarr[1].set_xlabel('Number of Epochs x 14', fontsize=18)\n",
    "    axarr[1].set_ylabel('Accuracy', fontsize=18)\n",
    "    axarr[1].set_ylim([0.7,1])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/features/'\n",
    "MODELPATH = 'output/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: LOADING DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CattleSoundDataset(Dataset):\n",
    "    \"\"\" FreeSound dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.len = X.shape[0]\n",
    "        self.x_data = torch.from_numpy(X)\n",
    "        self.y_data = torch.from_numpy(y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x_data[index], self.y_data[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('data/train_test/X_mfcc_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('data/train_test/X_mfcc_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('data/train_test/y_mfcc_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.load('data/train_test/y_mfcc_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1072, 60, 35)\n",
      "X_test: (460, 60, 35)\n",
      "y_train: (1072,)\n",
      "y_test: (460,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "\n",
    "print('X_test:', X_test.shape)\n",
    "\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CattleSoundDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CattleSoundDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: MAKING DATASET ITERABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_iters = 1000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size= batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {'train':len(train_loader.dataset),'valid':len(test_loader.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':train_loader,'valid':test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: CREATE MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=(1,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=(1,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=1, out_channels=32),\n",
    "            ConvBlock(in_channels=32, out_channels=64),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(7680, 1024),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #x = torch.mean(x, dim=3)\n",
    "        #x, _ = torch.max(x, dim=2)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: INSTANTIATE MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: INSTANTIATE LOSS CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: INSTANTIATE OPTIMIZER CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 7: TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs, graph=False):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history = pd.DataFrame()\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Calculate Accuracy         \n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = Variable(inputs.unsqueeze(1).cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs.unsqueeze(1)), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                outputs = model(inputs.to(dtype=torch.float))\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                \n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    y_pred += preds.cpu().numpy().tolist()\n",
    "                    y_true += labels.cpu().numpy().tolist()\n",
    "                    \n",
    "                else:\n",
    "                    y_pred += preds.numpy()\n",
    "                    y_true += labels.numpy()\n",
    "        \n",
    "                \n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            #epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            epoch_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_acc.append(epoch_acc)\n",
    "            else:\n",
    "                val_acc.append(epoch_acc)\n",
    "            \n",
    "            \n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    history['val_acc'] = val_acc\n",
    "    history['acc'] = train_acc\n",
    "    \n",
    "    if graph:\n",
    "        print()\n",
    "        print('==========' * 10)\n",
    "        plot_acc(history)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/28\n",
      "----------\n",
      "train Loss: 0.0040 Acc: 0.9444\n",
      "valid Loss: 0.0202 Acc: 0.7659\n",
      "\n",
      "Epoch 1/28\n",
      "----------\n",
      "train Loss: 0.0044 Acc: 0.9373\n",
      "valid Loss: 0.0200 Acc: 0.7678\n",
      "\n",
      "Epoch 2/28\n",
      "----------\n",
      "train Loss: 0.0051 Acc: 0.9331\n",
      "valid Loss: 0.0199 Acc: 0.7653\n",
      "\n",
      "Epoch 3/28\n",
      "----------\n",
      "train Loss: 0.0046 Acc: 0.9404\n",
      "valid Loss: 0.0200 Acc: 0.7635\n",
      "\n",
      "Epoch 4/28\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9365\n",
      "valid Loss: 0.0199 Acc: 0.7653\n",
      "\n",
      "Epoch 5/28\n",
      "----------\n",
      "train Loss: 0.0039 Acc: 0.9503\n",
      "valid Loss: 0.0198 Acc: 0.7629\n",
      "\n",
      "Epoch 6/28\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 0.9261\n",
      "valid Loss: 0.0196 Acc: 0.7653\n",
      "\n",
      "Epoch 7/28\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 0.9406\n",
      "valid Loss: 0.0199 Acc: 0.7513\n",
      "\n",
      "Epoch 8/28\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9504\n",
      "valid Loss: 0.0197 Acc: 0.7592\n",
      "\n",
      "Epoch 9/28\n",
      "----------\n",
      "train Loss: 0.0044 Acc: 0.9383\n",
      "valid Loss: 0.0197 Acc: 0.7612\n",
      "\n",
      "Epoch 10/28\n",
      "----------\n",
      "train Loss: 0.0039 Acc: 0.9516\n",
      "valid Loss: 0.0201 Acc: 0.7678\n",
      "\n",
      "Epoch 11/28\n",
      "----------\n",
      "train Loss: 0.0048 Acc: 0.9314\n",
      "valid Loss: 0.0198 Acc: 0.7605\n",
      "\n",
      "Epoch 12/28\n",
      "----------\n",
      "train Loss: 0.0051 Acc: 0.9462\n",
      "valid Loss: 0.0201 Acc: 0.7653\n",
      "\n",
      "Epoch 13/28\n",
      "----------\n",
      "train Loss: 0.0044 Acc: 0.9380\n",
      "valid Loss: 0.0199 Acc: 0.7653\n",
      "\n",
      "Epoch 14/28\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9457\n",
      "valid Loss: 0.0197 Acc: 0.7678\n",
      "\n",
      "Epoch 15/28\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9455\n",
      "valid Loss: 0.0200 Acc: 0.7664\n",
      "\n",
      "Epoch 16/28\n",
      "----------\n",
      "train Loss: 0.0041 Acc: 0.9538\n",
      "valid Loss: 0.0196 Acc: 0.7653\n",
      "\n",
      "Epoch 17/28\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 0.9321\n",
      "valid Loss: 0.0195 Acc: 0.7653\n",
      "\n",
      "Epoch 18/28\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9314\n",
      "valid Loss: 0.0198 Acc: 0.7659\n",
      "\n",
      "Epoch 19/28\n",
      "----------\n",
      "train Loss: 0.0052 Acc: 0.9284\n",
      "valid Loss: 0.0203 Acc: 0.7664\n",
      "\n",
      "Epoch 20/28\n",
      "----------\n",
      "train Loss: 0.0050 Acc: 0.9291\n",
      "valid Loss: 0.0198 Acc: 0.7653\n",
      "\n",
      "Epoch 21/28\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9425\n",
      "valid Loss: 0.0201 Acc: 0.7659\n",
      "\n",
      "Epoch 22/28\n",
      "----------\n",
      "train Loss: 0.0046 Acc: 0.9370\n",
      "valid Loss: 0.0200 Acc: 0.7635\n",
      "\n",
      "Epoch 23/28\n",
      "----------\n",
      "train Loss: 0.0042 Acc: 0.9472\n",
      "valid Loss: 0.0199 Acc: 0.7653\n",
      "\n",
      "Epoch 24/28\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9413\n",
      "valid Loss: 0.0199 Acc: 0.7659\n",
      "\n",
      "Epoch 25/28\n",
      "----------\n",
      "train Loss: 0.0046 Acc: 0.9446\n",
      "valid Loss: 0.0197 Acc: 0.7611\n",
      "\n",
      "Epoch 26/28\n",
      "----------\n",
      "train Loss: 0.0044 Acc: 0.9389\n",
      "valid Loss: 0.0198 Acc: 0.7635\n",
      "\n",
      "Epoch 27/28\n",
      "----------\n",
      "train Loss: 0.0047 Acc: 0.9452\n",
      "valid Loss: 0.0199 Acc: 0.7606\n",
      "\n",
      "Epoch 28/28\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 0.9388\n",
      "valid Loss: 0.0198 Acc: 0.7592\n",
      "\n",
      "Training complete in 0m 15s\n",
      "Best val Acc: 0.767782\n",
      "\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs, graph=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv.0.conv1.0.weight \t torch.Size([32, 1, 3, 3])\n",
      "conv.0.conv1.0.bias \t torch.Size([32])\n",
      "conv.0.conv1.1.weight \t torch.Size([32])\n",
      "conv.0.conv1.1.bias \t torch.Size([32])\n",
      "conv.0.conv1.1.running_mean \t torch.Size([32])\n",
      "conv.0.conv1.1.running_var \t torch.Size([32])\n",
      "conv.0.conv1.1.num_batches_tracked \t torch.Size([])\n",
      "conv.0.conv2.0.weight \t torch.Size([32, 32, 3, 3])\n",
      "conv.0.conv2.0.bias \t torch.Size([32])\n",
      "conv.0.conv2.1.weight \t torch.Size([32])\n",
      "conv.0.conv2.1.bias \t torch.Size([32])\n",
      "conv.0.conv2.1.running_mean \t torch.Size([32])\n",
      "conv.0.conv2.1.running_var \t torch.Size([32])\n",
      "conv.0.conv2.1.num_batches_tracked \t torch.Size([])\n",
      "conv.1.conv1.0.weight \t torch.Size([64, 32, 3, 3])\n",
      "conv.1.conv1.0.bias \t torch.Size([64])\n",
      "conv.1.conv1.1.weight \t torch.Size([64])\n",
      "conv.1.conv1.1.bias \t torch.Size([64])\n",
      "conv.1.conv1.1.running_mean \t torch.Size([64])\n",
      "conv.1.conv1.1.running_var \t torch.Size([64])\n",
      "conv.1.conv1.1.num_batches_tracked \t torch.Size([])\n",
      "conv.1.conv2.0.weight \t torch.Size([64, 64, 3, 3])\n",
      "conv.1.conv2.0.bias \t torch.Size([64])\n",
      "conv.1.conv2.1.weight \t torch.Size([64])\n",
      "conv.1.conv2.1.bias \t torch.Size([64])\n",
      "conv.1.conv2.1.running_mean \t torch.Size([64])\n",
      "conv.1.conv2.1.running_var \t torch.Size([64])\n",
      "conv.1.conv2.1.num_batches_tracked \t torch.Size([])\n",
      "fc.1.weight \t torch.Size([1024, 7680])\n",
      "fc.1.bias \t torch.Size([1024])\n",
      "fc.2.weight \t torch.Size([1])\n",
      "fc.3.weight \t torch.Size([1024])\n",
      "fc.3.bias \t torch.Size([1024])\n",
      "fc.3.running_mean \t torch.Size([1024])\n",
      "fc.3.running_var \t torch.Size([1024])\n",
      "fc.3.num_batches_tracked \t torch.Size([])\n",
      "fc.5.weight \t torch.Size([3, 1024])\n",
      "fc.5.bias \t torch.Size([3])\n",
      "Optimizer's state_dicat:\n",
      "state \t {140228500830392: {'step': 986, 'exp_avg': tensor([[[[ 3.8296e-04,  1.9491e-03,  1.9267e-04],\n",
      "          [ 2.5199e-04, -2.8042e-04,  4.7061e-04],\n",
      "          [ 2.1044e-03, -1.3766e-03, -9.0472e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.6661e-03, -3.6512e-03, -6.3367e-03],\n",
      "          [-5.9736e-03, -6.2729e-03, -1.2778e-02],\n",
      "          [ 4.2942e-04, -3.7080e-03, -1.9079e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5195e-03,  6.0449e-03,  4.8625e-03],\n",
      "          [ 8.3278e-03,  4.2388e-03,  3.9131e-03],\n",
      "          [ 6.5118e-03,  3.6463e-03,  5.5779e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3487e-04, -8.3387e-05,  1.4662e-03],\n",
      "          [-1.7686e-04, -1.8517e-04, -5.1406e-04],\n",
      "          [-3.3758e-04, -5.9547e-04,  1.1072e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1276e-03, -2.1687e-03, -3.9377e-03],\n",
      "          [ 3.1736e-04, -4.9568e-03, -2.9676e-03],\n",
      "          [ 2.7330e-03, -2.9902e-03, -2.6943e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6843e-04, -5.3009e-04, -1.2075e-03],\n",
      "          [-9.6063e-04,  9.0089e-04,  7.1189e-04],\n",
      "          [-1.8397e-03,  2.9003e-04, -1.0768e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.1837e-04, -8.5933e-04, -9.5435e-04],\n",
      "          [ 8.1637e-04,  7.1851e-04, -5.7708e-04],\n",
      "          [-1.5318e-03, -7.2710e-04, -1.1185e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3206e-04, -5.5022e-04,  9.3918e-04],\n",
      "          [ 1.1979e-03, -1.4391e-03, -4.6725e-04],\n",
      "          [ 3.9244e-04, -9.5947e-04, -3.0807e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.4359e-03,  1.8488e-03,  1.0517e-03],\n",
      "          [-1.4444e-03,  2.0228e-03,  2.2888e-03],\n",
      "          [-3.4538e-03,  1.7198e-03,  3.2376e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3423e-03,  1.6484e-03, -4.5789e-04],\n",
      "          [ 2.2942e-03, -1.6512e-04,  2.2056e-03],\n",
      "          [ 6.1480e-03, -1.3541e-03,  2.7785e-04]]],\n",
      "\n",
      "\n",
      "        [[[-9.7038e-04, -8.6035e-04, -2.0163e-03],\n",
      "          [-2.7846e-05, -1.1079e-03,  3.3557e-04],\n",
      "          [-2.6585e-03, -1.0740e-03, -6.2171e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0739e-03,  4.9364e-03,  9.6877e-04],\n",
      "          [-2.9720e-04,  4.8136e-04, -7.8314e-04],\n",
      "          [-2.2615e-03, -5.7471e-04, -1.7503e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9928e-03, -4.0982e-03, -2.4290e-03],\n",
      "          [ 1.4499e-03, -1.0538e-03, -3.8178e-03],\n",
      "          [ 3.6103e-04, -9.3255e-04, -1.8112e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0214e-03, -3.5724e-05, -1.2857e-03],\n",
      "          [-1.7703e-03,  1.4073e-03, -8.8039e-04],\n",
      "          [ 8.7382e-04, -7.5178e-05, -2.2962e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.2734e-03, -4.6785e-03, -7.0369e-04],\n",
      "          [-5.0364e-03, -6.1634e-03, -5.0562e-03],\n",
      "          [-4.2419e-03, -5.4223e-03, -3.7902e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1430e-03,  6.6803e-03,  4.6963e-03],\n",
      "          [ 6.6327e-03,  7.5793e-03,  9.0397e-03],\n",
      "          [ 1.7350e-02,  7.7348e-03,  3.2578e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4228e-04,  1.0200e-04, -1.4307e-04],\n",
      "          [-1.0199e-03,  4.4386e-04, -1.1066e-03],\n",
      "          [ 2.0151e-04, -3.8182e-04, -2.3718e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.2155e-04, -2.7781e-03, -6.5243e-03],\n",
      "          [-1.6737e-03, -2.4141e-03, -3.4386e-03],\n",
      "          [-1.0285e-03, -2.3713e-03, -3.8392e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9186e-03, -3.8417e-03, -3.7600e-03],\n",
      "          [ 1.1567e-03, -3.9274e-04, -2.8796e-03],\n",
      "          [ 4.0821e-03,  1.0228e-03, -2.5773e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3767e-03,  8.2214e-04, -3.6473e-04],\n",
      "          [-4.7308e-05,  8.2717e-04, -1.6408e-03],\n",
      "          [ 3.0677e-03,  1.9875e-03, -6.2589e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4573e-04,  1.5487e-03, -2.1020e-03],\n",
      "          [-2.1382e-03, -2.4608e-03, -3.0758e-03],\n",
      "          [ 1.1681e-03,  1.0642e-03, -2.5210e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2817e-03,  3.6893e-03,  2.0793e-03],\n",
      "          [-7.8462e-04,  2.0330e-03,  3.0546e-03],\n",
      "          [-8.1508e-04,  1.6275e-03, -7.8901e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.9783e-03, -5.7602e-03, -5.1063e-03],\n",
      "          [-1.2823e-03, -8.4618e-03, -6.3576e-03],\n",
      "          [-3.8825e-04, -4.9071e-03, -3.3657e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6250e-03, -4.4532e-04, -2.8631e-04],\n",
      "          [ 1.8817e-03,  1.5405e-03,  6.5327e-04],\n",
      "          [ 2.1352e-03,  6.7973e-04, -1.9939e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1441e-03,  4.1689e-03, -2.6689e-03],\n",
      "          [ 9.8802e-03,  6.2794e-03, -1.1471e-02],\n",
      "          [ 6.1916e-03,  7.7421e-03, -1.5193e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.6754e-03, -3.2204e-03,  2.2953e-04],\n",
      "          [-2.9413e-03,  1.7468e-03,  2.2862e-03],\n",
      "          [ 1.9292e-03,  1.8353e-03,  1.4137e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0280e-03,  6.9495e-03,  1.1400e-03],\n",
      "          [-3.1855e-04,  4.2857e-03, -1.5565e-03],\n",
      "          [ 4.3953e-03,  6.2771e-03,  2.1070e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5953e-03, -3.2517e-03, -3.3571e-03],\n",
      "          [-6.7936e-03, -6.6931e-03, -3.4561e-03],\n",
      "          [-7.3414e-03, -6.3236e-03, -4.0714e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.7294e-03, -1.8568e-03, -2.6876e-03],\n",
      "          [-4.2757e-03, -5.6352e-03, -7.6437e-03],\n",
      "          [-4.8058e-03, -2.1613e-03, -7.0284e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0350e-03, -1.3934e-03, -4.9709e-03],\n",
      "          [ 4.7901e-04, -8.3215e-04, -2.8985e-03],\n",
      "          [-8.2796e-04, -6.7328e-04, -3.3389e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8551e-03, -3.2391e-03, -8.1895e-03],\n",
      "          [ 4.5329e-03, -4.1130e-03, -1.1430e-02],\n",
      "          [-3.3176e-03, -2.8080e-03, -3.0110e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7747e-03,  3.1992e-04,  6.9498e-05],\n",
      "          [ 4.4854e-03, -5.1552e-04,  1.5857e-03],\n",
      "          [ 1.1054e-03, -8.0114e-04,  1.6322e-03]]]], device='cuda:0'), 'exp_avg_sq': tensor([[[[1.3295e-04, 3.5737e-05, 6.8988e-05],\n",
      "          [1.4521e-04, 5.4800e-05, 1.0740e-04],\n",
      "          [1.4911e-04, 9.2942e-05, 1.2286e-04]]],\n",
      "\n",
      "\n",
      "        [[[2.5203e-04, 2.8378e-04, 4.4767e-04],\n",
      "          [3.1395e-04, 3.4004e-04, 4.2105e-04],\n",
      "          [3.9091e-04, 3.5142e-04, 4.7325e-04]]],\n",
      "\n",
      "\n",
      "        [[[3.5362e-04, 2.6523e-04, 3.0738e-04],\n",
      "          [3.0728e-04, 3.2618e-04, 3.6672e-04],\n",
      "          [3.2068e-04, 3.3128e-04, 3.2894e-04]]],\n",
      "\n",
      "\n",
      "        [[[2.3921e-06, 1.2164e-05, 1.4378e-05],\n",
      "          [1.0531e-05, 9.6105e-06, 3.3558e-06],\n",
      "          [1.5158e-05, 1.6700e-05, 2.0451e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.1271e-04, 2.3791e-04, 2.9709e-04],\n",
      "          [1.8937e-04, 2.6053e-04, 2.6035e-04],\n",
      "          [2.5820e-04, 2.6511e-04, 2.8484e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.9790e-04, 2.0836e-04, 2.1843e-04],\n",
      "          [1.5425e-04, 1.5991e-04, 2.2078e-04],\n",
      "          [1.6755e-04, 2.2809e-04, 2.0984e-04]]],\n",
      "\n",
      "\n",
      "        [[[3.6805e-05, 1.2926e-05, 1.1405e-05],\n",
      "          [3.3772e-05, 2.4637e-05, 2.2566e-05],\n",
      "          [6.2013e-05, 3.9862e-05, 2.1085e-05]]],\n",
      "\n",
      "\n",
      "        [[[4.6333e-06, 2.2616e-05, 2.5204e-05],\n",
      "          [1.0303e-05, 9.0470e-06, 2.7051e-05],\n",
      "          [1.6399e-05, 1.7899e-05, 2.1380e-05]]],\n",
      "\n",
      "\n",
      "        [[[4.4182e-05, 3.9241e-05, 4.0254e-05],\n",
      "          [3.9411e-05, 3.4755e-05, 3.3005e-05],\n",
      "          [2.9237e-05, 2.1343e-05, 3.1803e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.3332e-04, 2.1414e-04, 2.4616e-04],\n",
      "          [1.4231e-04, 1.0914e-04, 2.0943e-04],\n",
      "          [1.4049e-04, 1.4039e-04, 2.6729e-04]]],\n",
      "\n",
      "\n",
      "        [[[2.0593e-05, 1.2090e-05, 1.5657e-05],\n",
      "          [2.1308e-05, 7.9884e-06, 8.7410e-06],\n",
      "          [4.4382e-05, 2.8290e-05, 1.0165e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.9392e-04, 1.6261e-04, 1.8188e-04],\n",
      "          [1.9328e-04, 1.4910e-04, 1.3568e-04],\n",
      "          [2.2372e-04, 1.5078e-04, 1.1514e-04]]],\n",
      "\n",
      "\n",
      "        [[[5.2347e-05, 6.4610e-05, 7.7156e-05],\n",
      "          [4.8577e-05, 8.2751e-05, 7.8365e-05],\n",
      "          [5.8596e-05, 7.6028e-05, 7.2092e-05]]],\n",
      "\n",
      "\n",
      "        [[[5.7075e-06, 1.6317e-05, 5.2620e-05],\n",
      "          [1.0283e-05, 1.0091e-05, 5.1928e-05],\n",
      "          [2.2632e-05, 1.9069e-05, 6.4423e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.8621e-04, 1.9214e-04, 1.7153e-04],\n",
      "          [3.0201e-04, 1.9889e-04, 2.4775e-04],\n",
      "          [3.2656e-04, 1.5954e-04, 2.3856e-04]]],\n",
      "\n",
      "\n",
      "        [[[3.9159e-04, 4.0074e-04, 4.3411e-04],\n",
      "          [4.4681e-04, 3.8682e-04, 4.3775e-04],\n",
      "          [5.1142e-04, 4.5437e-04, 4.5151e-04]]],\n",
      "\n",
      "\n",
      "        [[[4.3817e-06, 2.4712e-05, 4.9606e-05],\n",
      "          [1.1697e-05, 2.8612e-05, 6.0142e-05],\n",
      "          [7.9375e-06, 3.7868e-05, 6.1863e-05]]],\n",
      "\n",
      "\n",
      "        [[[6.2617e-05, 7.7874e-05, 1.2152e-04],\n",
      "          [4.9355e-05, 9.2522e-05, 1.3437e-04],\n",
      "          [6.2967e-05, 1.2609e-04, 1.5048e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.7014e-04, 2.3051e-04, 1.4212e-04],\n",
      "          [1.1801e-04, 1.8097e-04, 8.2174e-05],\n",
      "          [1.5816e-04, 2.3585e-04, 1.4946e-04]]],\n",
      "\n",
      "\n",
      "        [[[4.6122e-04, 1.7034e-04, 3.0591e-04],\n",
      "          [3.0214e-04, 1.4408e-04, 2.5982e-04],\n",
      "          [3.7851e-04, 2.5647e-04, 2.2746e-04]]],\n",
      "\n",
      "\n",
      "        [[[3.5683e-05, 4.5734e-05, 7.2457e-05],\n",
      "          [3.3461e-05, 4.8731e-05, 7.8916e-05],\n",
      "          [4.1822e-05, 5.6302e-05, 7.2133e-05]]],\n",
      "\n",
      "\n",
      "        [[[8.8953e-05, 7.6692e-05, 8.9253e-05],\n",
      "          [1.3519e-05, 4.7354e-05, 7.9402e-05],\n",
      "          [6.8871e-05, 5.8546e-05, 1.2455e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.8810e-04, 1.8522e-04, 1.6155e-04],\n",
      "          [1.9573e-04, 1.7908e-04, 2.0406e-04],\n",
      "          [2.0394e-04, 1.5195e-04, 1.9840e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.7226e-05, 3.4949e-05, 3.8158e-05],\n",
      "          [2.2093e-05, 3.2527e-05, 3.9626e-05],\n",
      "          [2.0337e-05, 2.5010e-05, 3.6375e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.6234e-04, 4.3665e-04, 4.0093e-04],\n",
      "          [5.2391e-04, 5.8508e-04, 5.4324e-04],\n",
      "          [4.6432e-04, 4.7690e-04, 3.6998e-04]]],\n",
      "\n",
      "\n",
      "        [[[4.2561e-05, 3.2811e-05, 4.8546e-05],\n",
      "          [3.1725e-05, 2.2640e-05, 5.3561e-05],\n",
      "          [2.8187e-05, 2.8803e-05, 4.7155e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.9989e-04, 2.0386e-04, 2.7146e-04],\n",
      "          [2.2240e-04, 2.3437e-04, 2.2666e-04],\n",
      "          [2.3697e-04, 2.2411e-04, 2.5785e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.9303e-04, 1.7259e-04, 2.1220e-04],\n",
      "          [1.5848e-04, 1.8319e-04, 1.7778e-04],\n",
      "          [1.9871e-04, 1.6573e-04, 1.0750e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.9008e-04, 2.3311e-04, 2.4451e-04],\n",
      "          [2.1625e-04, 1.4573e-04, 2.3761e-04],\n",
      "          [2.5308e-04, 1.5845e-04, 2.4238e-04]]],\n",
      "\n",
      "\n",
      "        [[[7.3888e-05, 1.1016e-04, 1.2603e-04],\n",
      "          [2.8116e-05, 8.1464e-05, 1.3970e-04],\n",
      "          [4.1915e-05, 8.2325e-05, 1.6671e-04]]],\n",
      "\n",
      "\n",
      "        [[[1.4197e-04, 1.0835e-04, 1.2685e-04],\n",
      "          [8.1295e-05, 1.1699e-04, 1.3911e-04],\n",
      "          [5.2115e-05, 1.3050e-04, 1.3878e-04]]],\n",
      "\n",
      "\n",
      "        [[[7.4008e-05, 3.9378e-05, 8.1050e-05],\n",
      "          [5.4514e-05, 6.6057e-06, 5.9290e-05],\n",
      "          [5.5624e-05, 1.5526e-05, 5.6585e-05]]]], device='cuda:0')}, 140228500829672: {'step': 986, 'exp_avg': tensor([ 4.4200e-12,  2.4714e-10,  2.6893e-10,  3.6142e-11,  1.6357e-10,\n",
      "         6.3424e-11,  1.6867e-11, -2.7015e-11,  1.3935e-11,  1.0420e-10,\n",
      "         1.4177e-11,  2.9285e-10,  5.2941e-11,  1.1349e-10,  1.2151e-10,\n",
      "        -5.9222e-10,  7.5546e-11,  1.0864e-10, -6.1506e-12, -5.4116e-11,\n",
      "         8.4176e-11,  2.8196e-11, -1.7529e-10,  1.0670e-10,  4.0134e-10,\n",
      "        -1.4657e-10,  2.7069e-11, -1.1005e-10, -1.2162e-10, -1.3424e-10,\n",
      "         8.9692e-11,  3.9349e-11], device='cuda:0'), 'exp_avg_sq': tensor([7.4782e-20, 2.3777e-19, 2.3831e-19, 3.5917e-20, 1.5208e-19, 1.6451e-18,\n",
      "        4.0597e-20, 3.3802e-20, 4.0328e-19, 1.8217e-19, 2.8822e-20, 1.7521e-18,\n",
      "        8.0759e-19, 4.1482e-20, 2.3707e-19, 1.1210e-17, 5.0754e-20, 6.3802e-20,\n",
      "        1.8622e-19, 2.5008e-19, 6.0782e-19, 1.8109e-19, 1.8758e-18, 3.6996e-19,\n",
      "        3.1521e-18, 4.6342e-19, 2.3171e-19, 1.6163e-19, 1.6576e-19, 8.7892e-20,\n",
      "        1.0792e-18, 6.1012e-20], device='cuda:0')}, 140228500828232: {'step': 986, 'exp_avg': tensor([ 0.0044,  0.0014,  0.0024, -0.0026, -0.0040,  0.0061, -0.0037, -0.0038,\n",
      "         0.0022, -0.0054,  0.0015,  0.0032,  0.0023,  0.0067, -0.0075, -0.0056,\n",
      "        -0.0009, -0.0009, -0.0007,  0.0012, -0.0042, -0.0005,  0.0004,  0.0056,\n",
      "         0.0008,  0.0028, -0.0005, -0.0009,  0.0006, -0.0030,  0.0045, -0.0022],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([1.0306e-04, 1.8557e-04, 1.9661e-04, 9.4945e-05, 2.0365e-04, 2.1859e-04,\n",
      "        8.0920e-05, 8.6681e-05, 2.3328e-04, 1.0883e-04, 4.9598e-05, 2.8593e-04,\n",
      "        1.9075e-04, 7.3453e-05, 2.0332e-04, 2.1840e-04, 8.0452e-05, 1.1398e-04,\n",
      "        7.6486e-05, 1.2127e-04, 1.9674e-04, 6.3115e-05, 2.1870e-04, 1.9231e-04,\n",
      "        3.0576e-04, 2.0390e-04, 2.4854e-04, 1.3740e-04, 2.3467e-04, 9.1976e-05,\n",
      "        2.1693e-04, 5.6539e-05], device='cuda:0')}, 140228500828448: {'step': 986, 'exp_avg': tensor([ 0.0014,  0.0082,  0.0006, -0.0026, -0.0043, -0.0011, -0.0027, -0.0041,\n",
      "         0.0004, -0.0075,  0.0010, -0.0008,  0.0029,  0.0100,  0.0019,  0.0003,\n",
      "        -0.0013,  0.0026,  0.0026,  0.0004, -0.0037,  0.0006,  0.0005,  0.0022,\n",
      "         0.0011,  0.0023, -0.0029,  0.0062,  0.0016, -0.0037,  0.0068, -0.0027],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([1.5273e-04, 1.3841e-04, 8.9050e-05, 1.6017e-04, 1.0162e-04, 1.0891e-04,\n",
      "        1.4554e-04, 1.4003e-04, 1.1358e-04, 1.0169e-04, 7.8158e-05, 1.2064e-04,\n",
      "        9.1734e-05, 1.4586e-04, 1.5297e-04, 8.9084e-05, 1.3214e-04, 9.3164e-05,\n",
      "        1.1803e-04, 1.6079e-04, 9.1185e-05, 9.3238e-05, 1.1038e-04, 9.6374e-05,\n",
      "        1.3367e-04, 7.9567e-05, 1.1932e-04, 9.7473e-05, 1.2787e-04, 1.3588e-04,\n",
      "        9.7876e-05, 1.0493e-04], device='cuda:0')}, 140228500832120: {'step': 986, 'exp_avg': tensor([[[[-3.0597e-03,  1.0702e-03,  8.3744e-04],\n",
      "          [-2.0604e-04,  7.8179e-04,  3.9120e-03],\n",
      "          [-3.4915e-04, -1.6233e-03,  3.6333e-03]],\n",
      "\n",
      "         [[ 5.2155e-04, -2.3029e-03, -1.3219e-03],\n",
      "          [-8.5914e-04, -1.1324e-04,  1.9455e-03],\n",
      "          [ 7.7093e-04,  1.2336e-03,  5.5136e-04]],\n",
      "\n",
      "         [[ 3.2518e-03,  2.1709e-03,  1.1966e-04],\n",
      "          [ 1.7913e-03,  1.3910e-03, -1.5611e-03],\n",
      "          [ 3.1503e-03,  8.5381e-04, -2.3709e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0418e-04, -1.6322e-05, -4.1190e-04],\n",
      "          [-1.1523e-04, -7.7411e-04, -2.6275e-03],\n",
      "          [ 5.3927e-04,  6.2839e-04, -5.7781e-04]],\n",
      "\n",
      "         [[ 4.2957e-03,  2.9067e-03,  4.1957e-04],\n",
      "          [ 2.8953e-03, -6.9816e-05,  1.6990e-03],\n",
      "          [ 1.4793e-03,  1.0167e-03,  3.1425e-03]],\n",
      "\n",
      "         [[-1.2926e-03, -1.5462e-03,  7.6232e-04],\n",
      "          [-1.7038e-03, -2.8804e-03,  3.8296e-04],\n",
      "          [-1.2376e-03, -1.7230e-03, -1.8733e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.3288e-06, -3.3911e-03,  2.8096e-03],\n",
      "          [ 5.7814e-05,  8.3356e-04, -2.2719e-03],\n",
      "          [-2.7279e-03,  2.1810e-03, -9.7706e-04]],\n",
      "\n",
      "         [[ 5.7202e-03, -1.2023e-03, -3.9481e-04],\n",
      "          [-1.3723e-03, -1.2888e-03,  1.6565e-03],\n",
      "          [-1.1953e-03, -5.5806e-04,  3.3648e-03]],\n",
      "\n",
      "         [[ 1.1985e-03, -1.0140e-03, -7.7407e-04],\n",
      "          [ 1.8937e-03, -5.8372e-04,  5.7633e-04],\n",
      "          [ 4.0222e-03, -3.6368e-04, -7.5144e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9294e-04, -1.4276e-04, -2.7608e-04],\n",
      "          [ 5.3277e-04, -1.0812e-04,  1.3492e-03],\n",
      "          [ 2.6482e-03,  1.6170e-03,  1.3748e-04]],\n",
      "\n",
      "         [[ 3.1827e-03,  1.4179e-03,  8.2645e-04],\n",
      "          [ 2.9063e-03,  3.1859e-03, -2.1239e-03],\n",
      "          [ 1.1139e-03,  1.7084e-03,  1.5101e-03]],\n",
      "\n",
      "         [[ 3.3736e-04, -2.4722e-04, -6.8689e-04],\n",
      "          [-2.0878e-04, -1.2502e-04, -2.6746e-04],\n",
      "          [-1.0518e-03, -8.0890e-04, -4.0021e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3823e-04,  2.8649e-03,  2.1167e-03],\n",
      "          [-1.8832e-03,  2.6112e-03,  6.6533e-04],\n",
      "          [-9.9258e-04,  3.0829e-03,  1.9600e-03]],\n",
      "\n",
      "         [[-5.5742e-04,  2.9270e-04,  1.8618e-03],\n",
      "          [ 2.0352e-03, -3.9664e-04, -2.0493e-03],\n",
      "          [ 2.7742e-03,  1.6553e-04,  4.5613e-03]],\n",
      "\n",
      "         [[-1.0509e-03, -3.3628e-03, -2.7343e-03],\n",
      "          [ 1.9223e-03, -1.2180e-03, -2.3978e-03],\n",
      "          [-1.6612e-03,  1.8605e-03, -7.9165e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2213e-04,  7.5071e-05, -6.9402e-04],\n",
      "          [ 8.3141e-04, -1.2572e-04,  7.2018e-04],\n",
      "          [-8.8664e-04, -5.1466e-04,  1.4631e-03]],\n",
      "\n",
      "         [[-3.2773e-03,  4.7520e-04, -2.9450e-03],\n",
      "          [-9.4090e-04, -1.2919e-03, -1.5949e-03],\n",
      "          [ 4.4989e-03,  1.0312e-03, -2.0931e-04]],\n",
      "\n",
      "         [[-2.7758e-04, -1.7041e-04,  1.8473e-03],\n",
      "          [ 8.5145e-04,  4.1923e-04,  1.7096e-04],\n",
      "          [ 8.5482e-05, -7.5756e-04,  3.3951e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.5200e-04,  6.1771e-04,  6.1246e-05],\n",
      "          [ 3.1413e-04,  1.7583e-03,  1.7301e-03],\n",
      "          [-1.5830e-04, -1.8220e-04,  1.6853e-03]],\n",
      "\n",
      "         [[ 7.7493e-05,  1.5215e-03,  6.4906e-04],\n",
      "          [-3.2206e-03,  3.5133e-03,  2.0194e-03],\n",
      "          [ 1.3360e-03,  2.7090e-03,  1.1511e-03]],\n",
      "\n",
      "         [[ 1.4857e-03,  2.1736e-03,  3.6957e-03],\n",
      "          [-1.2185e-03, -4.1804e-03,  1.5286e-03],\n",
      "          [ 6.1335e-04, -1.3641e-03,  1.2895e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1334e-03,  1.6872e-03,  2.4494e-04],\n",
      "          [ 2.3220e-04,  3.1219e-04,  9.4015e-05],\n",
      "          [ 5.3092e-05, -8.6029e-04,  3.0694e-03]],\n",
      "\n",
      "         [[ 7.4499e-04,  5.4093e-05, -4.8393e-03],\n",
      "          [-2.0401e-03,  4.0415e-04, -6.4512e-04],\n",
      "          [ 1.1457e-03,  6.1423e-04, -9.2160e-04]],\n",
      "\n",
      "         [[-5.3424e-04,  1.2486e-03,  1.3883e-03],\n",
      "          [-1.2780e-03,  1.5740e-04, -1.6001e-03],\n",
      "          [-1.8076e-03,  1.2735e-03, -1.2403e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.1530e-03,  9.6129e-04,  3.3355e-03],\n",
      "          [-5.1371e-04, -4.3531e-04,  2.9887e-03],\n",
      "          [-1.7296e-03, -6.1738e-04,  2.0212e-03]],\n",
      "\n",
      "         [[ 5.6710e-04, -3.2389e-03, -5.4236e-04],\n",
      "          [-5.7665e-04,  3.1572e-05,  1.0296e-03],\n",
      "          [-4.8574e-03,  2.3003e-04,  1.9680e-03]],\n",
      "\n",
      "         [[-3.7878e-03, -2.9657e-03, -3.6110e-03],\n",
      "          [-2.7132e-03, -1.9577e-03, -8.2478e-04],\n",
      "          [ 1.5879e-03, -2.2701e-03, -2.4159e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6295e-03,  3.5552e-05,  4.0283e-04],\n",
      "          [-2.5515e-03, -8.0245e-04,  9.3606e-04],\n",
      "          [ 7.9338e-04, -1.0261e-03,  1.7837e-03]],\n",
      "\n",
      "         [[ 3.6379e-03,  4.0639e-03,  8.2253e-05],\n",
      "          [ 2.7489e-03,  3.3572e-03,  1.7283e-03],\n",
      "          [-6.0107e-04,  1.6289e-04,  1.8017e-03]],\n",
      "\n",
      "         [[-2.9428e-04, -5.0195e-04,  1.3968e-03],\n",
      "          [-9.0595e-04, -7.7665e-04, -7.0361e-05],\n",
      "          [-1.8083e-03, -8.5927e-04,  7.4989e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8950e-03,  1.9594e-03,  6.5790e-04],\n",
      "          [-3.1757e-04,  2.5471e-03, -1.5447e-03],\n",
      "          [ 1.0416e-03,  5.3760e-04, -2.9801e-03]],\n",
      "\n",
      "         [[ 2.1199e-03,  9.5907e-04,  1.4990e-03],\n",
      "          [ 1.3583e-03,  1.5611e-03,  3.0161e-03],\n",
      "          [-2.4341e-04, -1.3082e-03,  1.4810e-04]],\n",
      "\n",
      "         [[-1.7961e-03, -1.6373e-03,  1.3814e-04],\n",
      "          [-2.3759e-04, -5.9979e-04, -2.4561e-03],\n",
      "          [ 1.5521e-03, -3.1766e-03, -1.5059e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6037e-04,  2.1185e-04, -4.6849e-05],\n",
      "          [-1.1746e-03, -4.3476e-04,  3.5632e-05],\n",
      "          [ 1.0541e-03, -9.3858e-04,  2.8538e-05]],\n",
      "\n",
      "         [[-1.0273e-03, -6.4447e-04, -2.4124e-03],\n",
      "          [-2.0964e-03, -7.1569e-04, -2.0840e-03],\n",
      "          [-1.5616e-03, -2.9538e-03, -1.8031e-03]],\n",
      "\n",
      "         [[ 4.5961e-05,  6.4810e-04,  1.2159e-04],\n",
      "          [-4.7483e-04, -9.0934e-04, -5.4853e-04],\n",
      "          [-1.1640e-03,  3.3517e-04, -1.6233e-03]]]], device='cuda:0'), 'exp_avg_sq': tensor([[[[3.0552e-05, 5.1019e-05, 3.7614e-05],\n",
      "          [1.5847e-05, 5.0103e-05, 3.9442e-05],\n",
      "          [1.5524e-05, 3.5582e-05, 5.0725e-05]],\n",
      "\n",
      "         [[5.1810e-05, 6.5158e-05, 4.3691e-05],\n",
      "          [2.9552e-05, 4.2430e-05, 3.5494e-05],\n",
      "          [2.7931e-05, 3.0699e-05, 9.9486e-05]],\n",
      "\n",
      "         [[4.5278e-05, 3.7913e-05, 8.1392e-05],\n",
      "          [5.2108e-05, 4.0741e-05, 6.1449e-05],\n",
      "          [9.2513e-05, 8.5162e-05, 7.6186e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.0199e-05, 2.3399e-05, 2.5536e-05],\n",
      "          [1.4881e-05, 1.5284e-05, 6.2729e-05],\n",
      "          [3.8770e-05, 2.2831e-05, 3.9364e-05]],\n",
      "\n",
      "         [[1.4334e-04, 1.4037e-04, 1.0296e-04],\n",
      "          [1.5113e-04, 1.3407e-04, 1.1195e-04],\n",
      "          [1.4606e-04, 1.3711e-04, 1.2644e-04]],\n",
      "\n",
      "         [[1.9782e-05, 2.1819e-05, 1.9957e-05],\n",
      "          [2.1208e-05, 2.6080e-05, 1.7336e-05],\n",
      "          [2.1284e-05, 2.2447e-05, 2.1966e-05]]],\n",
      "\n",
      "\n",
      "        [[[5.5300e-05, 9.2516e-05, 1.1833e-04],\n",
      "          [5.4433e-05, 7.3474e-05, 9.2306e-05],\n",
      "          [7.0491e-05, 8.0540e-05, 8.6413e-05]],\n",
      "\n",
      "         [[1.5212e-04, 1.4633e-04, 1.4130e-04],\n",
      "          [1.6716e-04, 9.5438e-05, 1.3522e-04],\n",
      "          [1.6974e-04, 9.1773e-05, 8.1625e-05]],\n",
      "\n",
      "         [[1.3931e-04, 1.4088e-04, 1.3558e-04],\n",
      "          [2.0022e-04, 1.9904e-04, 1.1893e-04],\n",
      "          [1.4912e-04, 1.7978e-04, 7.1053e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[8.4031e-05, 2.6351e-05, 3.6457e-05],\n",
      "          [9.2789e-05, 6.3345e-05, 3.7774e-05],\n",
      "          [7.0877e-05, 7.5404e-05, 5.2697e-05]],\n",
      "\n",
      "         [[1.6969e-04, 1.7909e-04, 1.9442e-04],\n",
      "          [1.7704e-04, 1.8373e-04, 2.1172e-04],\n",
      "          [1.9710e-04, 1.9096e-04, 1.9135e-04]],\n",
      "\n",
      "         [[3.1469e-05, 2.3875e-05, 4.6836e-05],\n",
      "          [4.4774e-05, 2.3340e-05, 4.8055e-05],\n",
      "          [4.6622e-05, 2.3964e-05, 3.7741e-05]]],\n",
      "\n",
      "\n",
      "        [[[5.7984e-05, 4.6254e-05, 4.6742e-05],\n",
      "          [7.9281e-05, 5.3396e-05, 3.1749e-05],\n",
      "          [6.3495e-05, 5.4592e-05, 3.6004e-05]],\n",
      "\n",
      "         [[5.8314e-05, 2.6953e-05, 6.1096e-05],\n",
      "          [7.2504e-05, 3.8488e-05, 3.8676e-05],\n",
      "          [7.1111e-05, 8.5592e-05, 1.0484e-04]],\n",
      "\n",
      "         [[7.0952e-05, 4.8757e-05, 5.9053e-05],\n",
      "          [1.6134e-04, 1.8624e-04, 1.4728e-04],\n",
      "          [6.2692e-05, 6.5414e-05, 6.8081e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.7577e-05, 2.6903e-05, 2.3257e-05],\n",
      "          [2.0628e-05, 3.1867e-05, 4.4627e-05],\n",
      "          [2.3719e-05, 3.0144e-05, 4.9474e-05]],\n",
      "\n",
      "         [[9.5218e-05, 7.1613e-05, 9.3634e-05],\n",
      "          [1.0898e-04, 1.0227e-04, 6.5775e-05],\n",
      "          [9.2377e-05, 1.0751e-04, 7.5256e-05]],\n",
      "\n",
      "         [[1.9889e-05, 2.3205e-05, 3.1010e-05],\n",
      "          [2.2128e-05, 2.4467e-05, 2.3461e-05],\n",
      "          [1.8186e-05, 1.9570e-05, 2.4032e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[3.7517e-05, 1.3320e-05, 1.7162e-05],\n",
      "          [4.2808e-05, 1.3890e-05, 2.3724e-05],\n",
      "          [4.3029e-05, 2.2452e-05, 3.9852e-05]],\n",
      "\n",
      "         [[5.5657e-05, 6.9296e-05, 7.2164e-05],\n",
      "          [7.8572e-05, 7.1982e-05, 6.2854e-05],\n",
      "          [9.3232e-05, 5.7214e-05, 8.1232e-05]],\n",
      "\n",
      "         [[1.3769e-04, 1.5022e-04, 1.0185e-04],\n",
      "          [6.1396e-05, 1.2155e-04, 7.7533e-05],\n",
      "          [7.0560e-05, 9.5086e-05, 7.1935e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.4978e-05, 3.1030e-05, 2.9836e-05],\n",
      "          [2.9492e-05, 2.6230e-05, 4.0948e-05],\n",
      "          [2.9991e-05, 2.9761e-05, 4.1237e-05]],\n",
      "\n",
      "         [[4.9380e-05, 4.9953e-05, 1.2607e-04],\n",
      "          [5.9744e-05, 9.3077e-05, 1.1745e-04],\n",
      "          [5.3088e-05, 1.0781e-04, 1.1736e-04]],\n",
      "\n",
      "         [[2.1645e-05, 2.2998e-05, 2.6468e-05],\n",
      "          [2.1190e-05, 2.2795e-05, 2.0571e-05],\n",
      "          [2.2199e-05, 2.0640e-05, 2.1073e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.7760e-05, 2.3370e-05, 5.5508e-05],\n",
      "          [4.6253e-05, 2.3267e-05, 5.8140e-05],\n",
      "          [3.6469e-05, 2.7398e-05, 4.8776e-05]],\n",
      "\n",
      "         [[6.9829e-05, 8.8405e-05, 8.9124e-05],\n",
      "          [1.0482e-04, 6.5264e-05, 1.1585e-04],\n",
      "          [8.6017e-05, 6.2489e-05, 1.1417e-04]],\n",
      "\n",
      "         [[1.3211e-04, 8.0605e-05, 9.7064e-05],\n",
      "          [9.3891e-05, 6.6576e-05, 4.7416e-05],\n",
      "          [1.4085e-04, 8.2341e-05, 3.2102e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[5.2172e-05, 1.7295e-05, 6.2025e-05],\n",
      "          [4.0631e-05, 3.0663e-05, 3.0188e-05],\n",
      "          [3.9103e-05, 4.5578e-05, 2.7786e-05]],\n",
      "\n",
      "         [[1.3479e-04, 1.5016e-04, 1.6021e-04],\n",
      "          [1.4499e-04, 1.7592e-04, 1.6968e-04],\n",
      "          [1.4788e-04, 1.6603e-04, 1.3787e-04]],\n",
      "\n",
      "         [[2.4102e-05, 2.8610e-05, 2.4939e-05],\n",
      "          [2.6116e-05, 1.8319e-05, 2.8909e-05],\n",
      "          [3.0081e-05, 1.8590e-05, 3.3507e-05]]],\n",
      "\n",
      "\n",
      "        [[[5.2170e-05, 2.1532e-05, 4.3194e-05],\n",
      "          [3.8424e-05, 4.0554e-05, 3.3833e-05],\n",
      "          [4.3295e-05, 1.5275e-05, 3.5736e-05]],\n",
      "\n",
      "         [[1.0460e-04, 5.9466e-05, 5.5846e-05],\n",
      "          [9.8199e-05, 1.0121e-04, 8.0704e-05],\n",
      "          [6.4543e-05, 6.1466e-05, 3.8338e-05]],\n",
      "\n",
      "         [[8.3431e-05, 1.0807e-04, 5.3202e-05],\n",
      "          [7.0287e-05, 5.9631e-05, 3.7312e-05],\n",
      "          [8.2712e-05, 4.8492e-05, 2.7924e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.0768e-05, 3.9423e-05, 1.9133e-05],\n",
      "          [1.8462e-05, 1.5875e-05, 8.8366e-06],\n",
      "          [4.6116e-05, 8.7126e-06, 9.5204e-06]],\n",
      "\n",
      "         [[9.6128e-05, 6.9496e-05, 6.6184e-05],\n",
      "          [9.4746e-05, 5.8478e-05, 6.0277e-05],\n",
      "          [1.0321e-04, 7.3397e-05, 7.1562e-05]],\n",
      "\n",
      "         [[2.4208e-05, 8.1707e-06, 1.3558e-05],\n",
      "          [1.2502e-05, 7.2065e-06, 1.2169e-05],\n",
      "          [1.1238e-05, 7.6718e-06, 1.2066e-05]]]], device='cuda:0')}, 140228500828736: {'step': 986, 'exp_avg': tensor([-1.5491e-08,  6.8484e-09,  5.5714e-09,  1.6832e-09, -9.7071e-10,\n",
      "         1.9778e-08,  9.2248e-10, -4.3470e-10,  1.0708e-09,  2.1658e-09,\n",
      "         8.6175e-09,  1.8156e-10, -1.0190e-09, -4.1572e-09,  1.2562e-08,\n",
      "         4.2711e-09, -6.8308e-09,  1.0784e-08,  1.1286e-09,  1.4348e-08,\n",
      "        -2.6048e-09, -2.0712e-08, -2.3397e-09, -6.2797e-09,  1.1885e-09,\n",
      "        -7.8133e-09, -1.1556e-08, -2.3485e-09,  4.9677e-09,  1.4647e-09,\n",
      "        -5.6766e-11,  3.2074e-09], device='cuda:0'), 'exp_avg_sq': tensor([6.0001e-16, 1.4876e-15, 8.6099e-16, 2.2658e-16, 1.0590e-15, 3.0893e-15,\n",
      "        2.8320e-16, 3.0713e-16, 3.6135e-16, 1.0495e-15, 7.2924e-16, 6.4469e-16,\n",
      "        4.1660e-16, 1.3607e-15, 1.3078e-15, 7.7116e-16, 1.1136e-15, 9.2131e-16,\n",
      "        1.4463e-15, 5.9970e-16, 2.6156e-16, 4.5053e-15, 6.4078e-16, 6.8747e-16,\n",
      "        1.5535e-15, 7.3510e-16, 9.7897e-16, 1.2969e-15, 6.3035e-16, 6.0831e-16,\n",
      "        6.9167e-16, 6.8496e-16], device='cuda:0')}, 140228500837792: {'step': 986, 'exp_avg': tensor([ 4.2104e-03, -8.2394e-04,  1.8113e-03, -6.2900e-04, -2.1190e-03,\n",
      "        -1.4908e-03,  1.0927e-05,  2.7728e-03, -5.5511e-04, -3.6979e-03,\n",
      "        -1.4415e-03, -1.2164e-03,  4.2751e-03, -2.4954e-03, -1.3292e-03,\n",
      "         2.2101e-03,  5.0545e-03,  1.0994e-03, -2.2025e-03,  4.9137e-03,\n",
      "        -1.7568e-03, -1.9795e-03, -3.6323e-03,  2.1767e-03, -7.1809e-04,\n",
      "        -1.4003e-03,  1.1188e-03, -3.7171e-03,  4.7095e-03,  2.9595e-03,\n",
      "        -9.8855e-04, -5.2901e-03], device='cuda:0'), 'exp_avg_sq': tensor([6.0165e-05, 2.1149e-04, 1.2773e-04, 3.6135e-05, 1.7303e-04, 7.3903e-05,\n",
      "        3.9532e-05, 3.6422e-05, 2.9076e-05, 1.6691e-04, 1.5158e-04, 1.2606e-04,\n",
      "        7.4335e-05, 2.2412e-04, 2.1528e-04, 9.3421e-05, 1.6113e-04, 1.5964e-04,\n",
      "        1.4184e-04, 2.3130e-04, 5.9050e-05, 1.6997e-04, 8.8819e-05, 1.1834e-04,\n",
      "        1.6813e-04, 1.7246e-04, 9.8308e-05, 1.8171e-04, 9.7520e-05, 9.7229e-05,\n",
      "        9.9330e-05, 1.6403e-04], device='cuda:0')}, 140228500839952: {'step': 986, 'exp_avg': tensor([ 5.1468e-04, -3.2248e-03,  9.6900e-04, -1.8615e-04,  1.4248e-03,\n",
      "         1.8574e-03,  1.1295e-04,  1.2921e-03,  3.2424e-04, -1.9389e-03,\n",
      "        -7.7112e-04, -2.9523e-03,  1.2164e-03,  6.2308e-04,  1.9772e-04,\n",
      "         3.6857e-04,  2.6213e-03,  1.6748e-03,  8.4540e-04,  4.6972e-03,\n",
      "        -1.5406e-04,  9.1202e-04, -1.4350e-03,  2.1667e-03,  3.2922e-04,\n",
      "         6.5822e-05,  2.2244e-03,  2.2943e-03,  2.9885e-03,  1.3633e-03,\n",
      "        -1.0897e-03,  2.7624e-04], device='cuda:0'), 'exp_avg_sq': tensor([2.9854e-05, 5.8434e-05, 3.9837e-05, 3.6952e-05, 6.0337e-05, 2.4595e-05,\n",
      "        3.6910e-05, 2.8901e-05, 3.3234e-05, 4.8990e-05, 2.7391e-05, 2.2941e-05,\n",
      "        3.4439e-05, 5.1955e-05, 4.0810e-05, 2.4326e-05, 2.4572e-05, 2.7153e-05,\n",
      "        3.4898e-05, 6.8914e-05, 3.2369e-05, 2.5648e-05, 3.2818e-05, 2.9896e-05,\n",
      "        3.6093e-05, 3.7012e-05, 2.5799e-05, 4.4867e-05, 2.9256e-05, 3.8422e-05,\n",
      "        3.0216e-05, 5.0494e-05], device='cuda:0')}, 140228500840168: {'step': 986, 'exp_avg': tensor([[[[-6.7013e-04, -2.4839e-03,  7.4017e-04],\n",
      "          [-8.9058e-04, -6.5422e-04, -2.4965e-04],\n",
      "          [-1.9505e-03, -9.8834e-04, -1.3122e-04]],\n",
      "\n",
      "         [[ 2.5864e-04, -8.0450e-05,  5.0626e-03],\n",
      "          [ 9.6357e-04, -1.5465e-04,  2.3966e-03],\n",
      "          [-2.0559e-03, -7.0301e-04,  3.5132e-03]],\n",
      "\n",
      "         [[ 4.5740e-03,  2.0209e-03,  3.6388e-03],\n",
      "          [ 3.6599e-03,  1.4681e-03,  3.9810e-03],\n",
      "          [ 7.3106e-05, -1.2202e-03,  2.5259e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3681e-03,  3.0069e-03,  2.5063e-03],\n",
      "          [ 1.4441e-03,  1.6632e-03,  1.8336e-03],\n",
      "          [ 1.0192e-03,  4.0880e-03,  3.7289e-03]],\n",
      "\n",
      "         [[-2.5389e-03, -5.7542e-04,  3.7045e-03],\n",
      "          [-1.9210e-03,  2.8429e-03,  3.4912e-03],\n",
      "          [-2.9553e-03,  2.6328e-03,  3.8704e-03]],\n",
      "\n",
      "         [[-2.6091e-03, -3.2625e-03,  8.5805e-04],\n",
      "          [-9.0735e-04, -3.0370e-03,  1.3156e-03],\n",
      "          [-2.6384e-04,  5.3854e-06,  1.1847e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.6249e-04, -1.1849e-03, -3.7663e-04],\n",
      "          [ 1.2863e-03, -2.3143e-03,  2.4726e-04],\n",
      "          [ 2.6768e-04, -1.4482e-03, -1.2421e-03]],\n",
      "\n",
      "         [[-1.3941e-03, -1.3465e-03,  1.3095e-03],\n",
      "          [-6.7732e-04,  5.7164e-04,  1.4563e-03],\n",
      "          [ 8.1877e-04,  8.2709e-04,  1.8062e-03]],\n",
      "\n",
      "         [[ 9.3044e-04, -1.0695e-04, -2.2398e-03],\n",
      "          [ 2.0542e-03,  2.2996e-03, -1.4799e-03],\n",
      "          [ 3.0106e-03,  1.9202e-03, -1.1697e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5081e-04,  7.5421e-04,  5.8547e-04],\n",
      "          [ 8.2202e-04,  1.0710e-03,  2.0227e-03],\n",
      "          [ 2.3509e-03,  3.0522e-03,  2.6531e-03]],\n",
      "\n",
      "         [[-2.1937e-03, -2.2070e-04,  1.1811e-04],\n",
      "          [ 3.9195e-04,  2.7378e-04, -4.6609e-04],\n",
      "          [ 2.9399e-03,  7.3809e-04,  3.1358e-03]],\n",
      "\n",
      "         [[-1.5377e-03, -1.2512e-03,  2.1598e-03],\n",
      "          [-2.8991e-03, -1.1220e-03,  1.5320e-03],\n",
      "          [-5.0038e-04, -6.8785e-04,  2.7852e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0464e-03, -2.3875e-04, -1.1233e-03],\n",
      "          [-1.0410e-03,  2.9018e-04,  4.4987e-04],\n",
      "          [-9.7545e-05,  2.0276e-03,  7.6070e-04]],\n",
      "\n",
      "         [[-2.8093e-04, -1.4335e-04,  9.3184e-04],\n",
      "          [-1.4042e-03, -3.8347e-04, -1.3868e-03],\n",
      "          [ 4.9751e-04, -9.2387e-04, -1.1696e-03]],\n",
      "\n",
      "         [[-1.4760e-03,  4.0302e-04, -1.3782e-03],\n",
      "          [-1.4502e-03,  2.0965e-04, -8.0852e-04],\n",
      "          [-2.0818e-04,  6.8327e-04,  1.7881e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1860e-03, -6.6903e-04,  1.0039e-03],\n",
      "          [ 2.7584e-04, -9.9664e-04, -6.4435e-04],\n",
      "          [-6.4727e-04, -2.7079e-03,  6.8188e-04]],\n",
      "\n",
      "         [[-6.7496e-04, -1.1634e-04, -2.0547e-03],\n",
      "          [-1.9031e-04, -1.0163e-04, -1.6784e-03],\n",
      "          [-1.9153e-03, -1.5487e-03, -1.4126e-04]],\n",
      "\n",
      "         [[-1.1355e-03, -1.4807e-03,  2.7420e-04],\n",
      "          [-4.6818e-04,  8.8600e-05,  1.4642e-03],\n",
      "          [-4.6573e-04, -1.8250e-03, -4.8919e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.6088e-04,  7.4651e-04,  8.6826e-04],\n",
      "          [ 2.5173e-04, -1.5619e-04,  2.4873e-05],\n",
      "          [ 3.1461e-04, -1.2414e-03,  6.8484e-04]],\n",
      "\n",
      "         [[-1.4534e-03, -1.3558e-03,  3.1684e-04],\n",
      "          [-6.4656e-04,  6.8711e-04,  4.6372e-04],\n",
      "          [-1.4006e-03, -1.4059e-04, -4.4734e-04]],\n",
      "\n",
      "         [[-2.2460e-03, -1.6564e-03, -1.3071e-03],\n",
      "          [-6.4005e-04, -1.5069e-03,  6.4302e-04],\n",
      "          [ 2.8629e-04, -4.2518e-04, -1.5284e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.4272e-04,  8.5290e-04,  9.7477e-04],\n",
      "          [-3.4257e-04, -7.6537e-04, -1.4648e-04],\n",
      "          [ 4.2860e-04,  4.7273e-04, -3.6953e-04]],\n",
      "\n",
      "         [[ 2.1376e-04,  2.3729e-03, -5.5653e-04],\n",
      "          [-1.2780e-03,  6.1212e-04,  1.2876e-04],\n",
      "          [-1.4290e-04, -9.1381e-04, -3.6558e-04]],\n",
      "\n",
      "         [[ 5.8970e-04,  1.7284e-04, -8.8195e-04],\n",
      "          [-3.7984e-05,  1.5964e-04, -1.0881e-04],\n",
      "          [-1.8487e-04,  5.0587e-04, -1.5938e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7693e-04, -1.2045e-04, -1.2711e-03],\n",
      "          [ 1.2395e-04, -1.6065e-04,  1.0618e-03],\n",
      "          [ 7.7353e-04,  6.6288e-04,  3.1627e-04]],\n",
      "\n",
      "         [[ 2.5040e-03,  2.3332e-03, -3.7493e-04],\n",
      "          [ 2.2293e-04,  2.7394e-03, -9.9168e-04],\n",
      "          [ 7.2178e-04,  2.7504e-03, -4.5407e-04]],\n",
      "\n",
      "         [[-9.2383e-04,  1.4243e-03,  2.0040e-03],\n",
      "          [ 2.1977e-03,  2.4931e-03,  1.2415e-03],\n",
      "          [ 1.9588e-03,  1.8953e-03,  2.7802e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1822e-03,  1.8207e-03,  2.4778e-06],\n",
      "          [-1.7811e-04, -1.8255e-03, -5.1342e-04],\n",
      "          [ 3.1564e-04, -4.9086e-04, -1.2171e-03]],\n",
      "\n",
      "         [[-2.4024e-04,  1.3984e-03, -7.3409e-04],\n",
      "          [ 6.9319e-07,  6.6040e-04,  2.6519e-04],\n",
      "          [-1.0560e-03,  1.4561e-03,  1.2505e-03]],\n",
      "\n",
      "         [[-3.5390e-04, -1.8346e-03, -1.3928e-03],\n",
      "          [-8.8272e-04, -6.1105e-04, -1.7627e-03],\n",
      "          [ 3.3361e-04, -4.4189e-04, -2.0926e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4592e-04,  3.1630e-04,  1.0417e-03],\n",
      "          [-2.9327e-04, -2.2999e-04,  1.0424e-03],\n",
      "          [-3.6423e-04, -3.4163e-04,  6.4816e-04]],\n",
      "\n",
      "         [[ 2.7318e-04, -4.6570e-04,  1.4256e-03],\n",
      "          [-1.9937e-04, -1.0215e-03,  3.7276e-04],\n",
      "          [-4.6779e-04, -1.7247e-03,  1.2413e-04]],\n",
      "\n",
      "         [[-8.8144e-04, -4.4622e-04, -6.8804e-04],\n",
      "          [-7.5324e-04, -6.4378e-04, -1.2802e-03],\n",
      "          [-1.4891e-03, -1.5429e-03, -1.4212e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3098e-04,  8.2766e-04, -2.1488e-04],\n",
      "          [ 3.5564e-04,  3.7519e-04, -2.5245e-04],\n",
      "          [ 7.7918e-05, -6.0201e-04, -2.0689e-04]],\n",
      "\n",
      "         [[ 2.9976e-04,  7.1007e-04,  2.6453e-05],\n",
      "          [ 9.5443e-05,  1.2770e-03,  3.8605e-04],\n",
      "          [-3.1492e-04,  6.7654e-05,  1.9821e-04]],\n",
      "\n",
      "         [[ 9.4188e-05,  2.2650e-04,  1.0605e-03],\n",
      "          [ 1.0040e-04,  8.5936e-04,  1.8466e-04],\n",
      "          [ 1.2942e-04,  1.0233e-03, -7.3021e-05]]]], device='cuda:0'), 'exp_avg_sq': tensor([[[[3.1491e-05, 3.6576e-05, 3.4729e-05],\n",
      "          [3.1080e-05, 3.7519e-05, 3.5784e-05],\n",
      "          [3.2269e-05, 3.6942e-05, 3.2586e-05]],\n",
      "\n",
      "         [[7.9500e-05, 8.9155e-05, 7.9371e-05],\n",
      "          [9.1034e-05, 9.4535e-05, 8.3195e-05],\n",
      "          [8.0971e-05, 9.8985e-05, 8.5500e-05]],\n",
      "\n",
      "         [[7.7988e-05, 7.1909e-05, 6.7489e-05],\n",
      "          [8.0688e-05, 7.3362e-05, 6.9861e-05],\n",
      "          [7.8455e-05, 7.7250e-05, 7.1230e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.7412e-05, 4.2759e-05, 4.3176e-05],\n",
      "          [4.5712e-05, 4.1902e-05, 4.5024e-05],\n",
      "          [4.7071e-05, 4.4679e-05, 4.7807e-05]],\n",
      "\n",
      "         [[4.8212e-05, 5.2200e-05, 4.1890e-05],\n",
      "          [4.9494e-05, 5.1387e-05, 4.4553e-05],\n",
      "          [4.4858e-05, 5.0753e-05, 5.2364e-05]],\n",
      "\n",
      "         [[8.7613e-05, 7.1227e-05, 6.1267e-05],\n",
      "          [8.6854e-05, 7.2371e-05, 5.1789e-05],\n",
      "          [7.6758e-05, 7.0899e-05, 5.3278e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.6663e-05, 1.7262e-05, 1.4153e-05],\n",
      "          [1.9352e-05, 1.7790e-05, 1.4658e-05],\n",
      "          [1.9494e-05, 1.7349e-05, 1.6651e-05]],\n",
      "\n",
      "         [[4.1242e-05, 4.5567e-05, 4.2515e-05],\n",
      "          [4.5417e-05, 4.6795e-05, 3.9384e-05],\n",
      "          [4.3200e-05, 4.6469e-05, 5.1810e-05]],\n",
      "\n",
      "         [[3.8580e-05, 3.7005e-05, 4.1341e-05],\n",
      "          [4.1157e-05, 3.7303e-05, 3.8233e-05],\n",
      "          [3.8640e-05, 3.3201e-05, 3.8684e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3574e-05, 2.3334e-05, 2.7775e-05],\n",
      "          [2.3258e-05, 2.5835e-05, 2.7412e-05],\n",
      "          [2.4314e-05, 2.8525e-05, 2.4151e-05]],\n",
      "\n",
      "         [[2.5712e-05, 2.7433e-05, 2.3787e-05],\n",
      "          [2.6466e-05, 3.0069e-05, 2.8371e-05],\n",
      "          [2.8805e-05, 3.1458e-05, 3.0667e-05]],\n",
      "\n",
      "         [[3.1858e-05, 2.9958e-05, 3.0805e-05],\n",
      "          [3.0575e-05, 2.8724e-05, 3.5420e-05],\n",
      "          [3.3516e-05, 2.5876e-05, 3.0965e-05]]],\n",
      "\n",
      "\n",
      "        [[[8.8768e-06, 1.0463e-05, 1.0705e-05],\n",
      "          [8.2625e-06, 1.0673e-05, 1.1894e-05],\n",
      "          [9.4616e-06, 9.8026e-06, 1.1374e-05]],\n",
      "\n",
      "         [[4.0353e-05, 4.1350e-05, 3.3626e-05],\n",
      "          [4.4714e-05, 4.2767e-05, 3.4813e-05],\n",
      "          [4.3770e-05, 4.0417e-05, 3.5695e-05]],\n",
      "\n",
      "         [[3.2122e-05, 3.1095e-05, 3.7544e-05],\n",
      "          [3.8188e-05, 3.7716e-05, 4.2928e-05],\n",
      "          [3.6419e-05, 3.2271e-05, 4.3432e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.5273e-05, 1.9566e-05, 1.9248e-05],\n",
      "          [1.6104e-05, 2.0319e-05, 1.8814e-05],\n",
      "          [1.7774e-05, 2.0405e-05, 1.8595e-05]],\n",
      "\n",
      "         [[1.8506e-05, 1.9859e-05, 2.0256e-05],\n",
      "          [1.7529e-05, 1.9003e-05, 2.3533e-05],\n",
      "          [1.9364e-05, 1.6915e-05, 2.0841e-05]],\n",
      "\n",
      "         [[1.9941e-05, 2.1637e-05, 3.7456e-05],\n",
      "          [1.8880e-05, 2.0613e-05, 3.9626e-05],\n",
      "          [1.7119e-05, 2.0955e-05, 3.8955e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[7.7186e-06, 7.1174e-06, 7.2728e-06],\n",
      "          [8.8455e-06, 6.3851e-06, 7.3571e-06],\n",
      "          [7.5338e-06, 7.3887e-06, 8.1486e-06]],\n",
      "\n",
      "         [[3.8097e-05, 3.5137e-05, 3.3415e-05],\n",
      "          [3.8064e-05, 3.6060e-05, 3.2689e-05],\n",
      "          [3.7291e-05, 3.6501e-05, 3.2068e-05]],\n",
      "\n",
      "         [[2.8626e-05, 2.7304e-05, 3.0954e-05],\n",
      "          [2.9824e-05, 2.6744e-05, 2.7791e-05],\n",
      "          [3.2646e-05, 2.9009e-05, 2.8096e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.3692e-05, 1.4116e-05, 1.7990e-05],\n",
      "          [1.2435e-05, 1.5319e-05, 1.6067e-05],\n",
      "          [1.5867e-05, 1.5703e-05, 1.9915e-05]],\n",
      "\n",
      "         [[1.6720e-05, 1.5648e-05, 1.5904e-05],\n",
      "          [1.5315e-05, 1.5754e-05, 1.4707e-05],\n",
      "          [1.9162e-05, 1.6409e-05, 1.6740e-05]],\n",
      "\n",
      "         [[1.4439e-05, 1.4874e-05, 2.4355e-05],\n",
      "          [1.2439e-05, 1.4249e-05, 2.3090e-05],\n",
      "          [1.5035e-05, 1.8924e-05, 2.7734e-05]]],\n",
      "\n",
      "\n",
      "        [[[1.5549e-05, 1.7572e-05, 1.8197e-05],\n",
      "          [1.5354e-05, 1.9405e-05, 1.5787e-05],\n",
      "          [1.3583e-05, 1.6885e-05, 1.6301e-05]],\n",
      "\n",
      "         [[3.8963e-05, 4.5771e-05, 4.5774e-05],\n",
      "          [4.2711e-05, 4.5738e-05, 4.3852e-05],\n",
      "          [4.4374e-05, 5.2260e-05, 4.6434e-05]],\n",
      "\n",
      "         [[2.9500e-05, 3.2792e-05, 3.5334e-05],\n",
      "          [3.5176e-05, 3.4323e-05, 3.6294e-05],\n",
      "          [2.7285e-05, 3.4358e-05, 3.8169e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.5350e-05, 2.5569e-05, 2.7998e-05],\n",
      "          [2.3789e-05, 2.3036e-05, 2.8057e-05],\n",
      "          [2.3668e-05, 2.0940e-05, 2.2496e-05]],\n",
      "\n",
      "         [[2.7429e-05, 2.7940e-05, 2.2908e-05],\n",
      "          [2.0949e-05, 2.5837e-05, 2.3431e-05],\n",
      "          [2.3894e-05, 2.3992e-05, 2.4111e-05]],\n",
      "\n",
      "         [[3.6085e-05, 3.5571e-05, 3.1311e-05],\n",
      "          [3.7598e-05, 3.5231e-05, 3.2759e-05],\n",
      "          [3.9454e-05, 3.3785e-05, 3.1384e-05]]],\n",
      "\n",
      "\n",
      "        [[[4.3451e-06, 5.8060e-06, 7.8198e-06],\n",
      "          [3.8909e-06, 5.0839e-06, 7.2585e-06],\n",
      "          [4.0601e-06, 5.4805e-06, 7.2394e-06]],\n",
      "\n",
      "         [[1.4088e-05, 2.5192e-05, 2.6284e-05],\n",
      "          [1.2183e-05, 2.5830e-05, 3.1609e-05],\n",
      "          [1.6808e-05, 2.9283e-05, 3.5560e-05]],\n",
      "\n",
      "         [[1.7249e-05, 1.4833e-05, 1.5609e-05],\n",
      "          [1.6246e-05, 1.4174e-05, 1.6774e-05],\n",
      "          [1.7392e-05, 1.7398e-05, 1.8250e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.8521e-06, 1.7054e-05, 1.3860e-05],\n",
      "          [8.7262e-06, 1.8307e-05, 1.5610e-05],\n",
      "          [9.8961e-06, 1.7428e-05, 1.5816e-05]],\n",
      "\n",
      "         [[6.4181e-06, 1.0046e-05, 1.1706e-05],\n",
      "          [7.3370e-06, 1.0042e-05, 1.1588e-05],\n",
      "          [8.0585e-06, 1.1498e-05, 1.0431e-05]],\n",
      "\n",
      "         [[8.6282e-06, 1.8812e-05, 3.2527e-05],\n",
      "          [7.9878e-06, 2.1365e-05, 3.3289e-05],\n",
      "          [9.5498e-06, 2.1285e-05, 3.3564e-05]]]], device='cuda:0')}, 140228500840240: {'step': 986, 'exp_avg': tensor([ 6.8401e-11, -3.6172e-10,  4.0954e-11, -5.5945e-10, -3.9697e-10,\n",
      "         5.0451e-10, -6.8052e-10,  2.5026e-10, -1.1781e-09,  7.2727e-10,\n",
      "         7.4912e-11,  1.4342e-10,  7.4972e-10, -1.8106e-10,  1.5591e-10,\n",
      "        -4.5700e-10, -8.3317e-10,  5.3123e-10, -1.1809e-09, -1.3464e-09,\n",
      "         5.7900e-10,  5.6148e-10, -2.3761e-10,  3.1807e-10,  1.0587e-09,\n",
      "         8.7291e-11,  5.1675e-11,  1.4923e-10, -1.9742e-09,  9.3366e-11,\n",
      "        -6.7258e-10, -6.5650e-10,  7.6161e-11,  2.0085e-09,  3.1893e-10,\n",
      "         7.4218e-10, -9.2151e-10,  4.9823e-10,  6.9460e-10, -1.4664e-10,\n",
      "        -2.5232e-10,  5.0863e-10,  2.7207e-10, -1.3624e-10, -5.9066e-10,\n",
      "        -4.8183e-10, -1.7943e-10, -1.1425e-09, -3.5837e-10, -1.0161e-09,\n",
      "        -4.8180e-10, -5.2393e-10,  3.3556e-10,  8.8344e-10,  8.4385e-10,\n",
      "         2.9009e-10, -9.0480e-10,  5.8034e-10,  2.3345e-10,  6.5114e-10,\n",
      "         4.9558e-10, -5.8537e-10,  1.0379e-09,  3.0730e-10], device='cuda:0'), 'exp_avg_sq': tensor([1.4562e-17, 7.3062e-18, 5.7849e-18, 6.2209e-18, 4.2440e-18, 5.9685e-18,\n",
      "        9.4125e-18, 6.9522e-18, 7.0820e-18, 3.7585e-18, 1.0102e-17, 5.3433e-18,\n",
      "        4.6585e-18, 6.3304e-18, 7.0534e-18, 1.1442e-17, 7.9030e-18, 6.7569e-18,\n",
      "        7.2175e-18, 9.5445e-18, 5.2540e-18, 7.0844e-18, 4.5959e-18, 5.7647e-18,\n",
      "        8.1198e-18, 3.6093e-18, 3.9321e-18, 7.4068e-18, 1.2309e-17, 6.8661e-18,\n",
      "        7.9666e-18, 7.1120e-18, 5.8043e-18, 7.8553e-18, 6.5121e-18, 7.9006e-18,\n",
      "        5.3176e-18, 7.7095e-18, 1.3681e-17, 8.0194e-18, 1.7438e-18, 6.3233e-18,\n",
      "        3.6994e-18, 6.2317e-18, 5.9395e-18, 2.5210e-18, 5.0401e-18, 7.6661e-18,\n",
      "        4.6239e-18, 8.2936e-18, 5.6912e-18, 5.3494e-18, 7.5257e-18, 8.3294e-18,\n",
      "        4.3238e-18, 5.8541e-18, 6.6355e-18, 5.5359e-18, 3.9266e-18, 5.6116e-18,\n",
      "        6.2194e-18, 5.2374e-18, 6.0441e-18, 4.3349e-18], device='cuda:0')}, 140228500839880: {'step': 986, 'exp_avg': tensor([ 4.0808e-04,  2.1575e-03, -2.6385e-04,  2.5226e-03,  1.7860e-03,\n",
      "        -5.8881e-05,  4.3654e-04,  4.6486e-04, -4.1125e-03, -1.2531e-03,\n",
      "         1.8403e-03,  1.6272e-03,  7.7734e-04, -1.6630e-04,  9.6297e-04,\n",
      "        -2.6373e-04, -2.1725e-03, -3.7655e-03,  1.4029e-03, -2.6399e-03,\n",
      "         3.7540e-04,  2.4941e-03, -5.8456e-04,  2.3045e-03,  2.2310e-03,\n",
      "         1.5045e-03, -1.1118e-04,  8.6654e-04,  1.6685e-03,  1.4838e-03,\n",
      "         3.5616e-05, -3.5278e-03,  3.1225e-03,  3.3913e-03, -3.1608e-03,\n",
      "        -3.0239e-03,  1.7416e-04, -7.6099e-04, -1.0015e-03,  1.0599e-03,\n",
      "        -7.6044e-04, -6.9712e-04, -1.0490e-03, -3.1644e-03, -3.4294e-03,\n",
      "         1.5084e-03,  3.6640e-03, -1.4357e-03,  4.4567e-04,  6.5513e-04,\n",
      "        -1.8368e-03, -1.3016e-03,  7.4025e-04,  3.1063e-04, -1.3714e-03,\n",
      "         7.1378e-04, -1.7671e-03, -1.5378e-03, -5.0391e-04,  1.3409e-03,\n",
      "         2.2764e-03, -1.5865e-03,  3.6688e-04,  4.1554e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.1462e-05, 5.3687e-05, 7.6780e-05, 2.5572e-05, 4.9873e-05, 5.6921e-05,\n",
      "        2.8071e-05, 3.3606e-05, 4.1003e-05, 7.0286e-05, 3.9342e-05, 4.2904e-05,\n",
      "        5.0524e-05, 4.4759e-05, 5.3907e-05, 3.9830e-05, 5.2170e-05, 5.6615e-05,\n",
      "        5.5039e-05, 2.3240e-05, 4.4683e-05, 3.4202e-05, 2.1918e-05, 2.3152e-05,\n",
      "        3.7122e-05, 7.4927e-05, 4.4425e-05, 1.0864e-04, 6.3167e-05, 4.0823e-05,\n",
      "        3.3051e-05, 5.4524e-05, 4.5892e-05, 6.3768e-05, 6.7531e-05, 3.8159e-05,\n",
      "        5.6970e-05, 2.6046e-05, 3.0906e-05, 4.2649e-05, 5.3349e-05, 2.8387e-05,\n",
      "        1.7751e-05, 4.8232e-05, 2.2881e-05, 2.1819e-05, 3.0143e-05, 3.6336e-05,\n",
      "        6.6906e-05, 5.4077e-05, 2.4555e-05, 4.6574e-05, 3.7982e-05, 2.1580e-05,\n",
      "        1.5446e-05, 1.9728e-05, 3.8100e-05, 2.5029e-05, 1.9978e-05, 4.9135e-05,\n",
      "        3.5416e-05, 8.6836e-05, 4.1195e-05, 3.7374e-05], device='cuda:0')}, 140228500840096: {'step': 986, 'exp_avg': tensor([-8.8801e-04,  3.7822e-05,  4.9589e-04,  1.7654e-03,  2.0448e-03,\n",
      "        -6.0892e-04,  3.0325e-03,  7.3760e-04, -2.9673e-03, -8.9041e-04,\n",
      "         5.8181e-05,  1.5621e-03,  4.7917e-04,  5.6514e-04, -2.1288e-03,\n",
      "        -1.4319e-04,  8.5983e-04, -3.4691e-03,  1.2647e-03, -1.5985e-03,\n",
      "         1.6451e-03,  1.1433e-03, -3.1560e-04,  2.6507e-03,  1.6181e-03,\n",
      "         1.2656e-03,  4.9822e-04,  2.2800e-03,  2.2630e-03,  2.8079e-03,\n",
      "        -1.6512e-03, -2.4778e-03,  2.2505e-03,  2.9967e-03, -1.6069e-03,\n",
      "        -2.5856e-03, -1.2226e-03,  5.7746e-04, -7.1703e-04, -4.7500e-04,\n",
      "         1.2229e-03,  6.7068e-04,  2.5124e-04, -3.6928e-03, -1.8800e-03,\n",
      "         1.2239e-03,  2.9639e-03,  5.0213e-04,  6.4504e-04,  2.0841e-03,\n",
      "         2.3161e-04,  6.4585e-04,  3.0168e-04,  3.4882e-04, -1.9901e-03,\n",
      "         6.0992e-04, -8.9862e-04, -1.4576e-03, -1.6927e-03, -3.8494e-04,\n",
      "         1.7349e-03,  1.1855e-03, -4.8631e-05,  1.1780e-03], device='cuda:0'), 'exp_avg_sq': tensor([2.9936e-05, 2.2317e-05, 3.1895e-05, 2.8878e-05, 2.3944e-05, 2.7442e-05,\n",
      "        2.6344e-05, 2.6208e-05, 2.3527e-05, 2.7621e-05, 2.3126e-05, 2.1723e-05,\n",
      "        2.7057e-05, 2.2807e-05, 2.7590e-05, 2.7910e-05, 2.2580e-05, 2.8776e-05,\n",
      "        2.7520e-05, 3.5555e-05, 3.0702e-05, 1.9237e-05, 2.9929e-05, 2.6161e-05,\n",
      "        2.9551e-05, 4.4527e-05, 2.0707e-05, 6.1309e-05, 3.0738e-05, 2.8296e-05,\n",
      "        2.1766e-05, 2.5972e-05, 2.0231e-05, 3.3612e-05, 3.0341e-05, 2.2912e-05,\n",
      "        2.8001e-05, 2.4448e-05, 3.1412e-05, 2.3355e-05, 3.6577e-05, 2.5400e-05,\n",
      "        2.3010e-05, 2.7718e-05, 2.8047e-05, 2.5980e-05, 4.2943e-05, 2.7078e-05,\n",
      "        3.4203e-05, 3.3993e-05, 2.4834e-05, 2.0775e-05, 3.7276e-05, 2.3878e-05,\n",
      "        2.1031e-05, 2.5330e-05, 2.2192e-05, 2.4165e-05, 2.4514e-05, 2.5999e-05,\n",
      "        2.8097e-05, 4.2222e-05, 2.4140e-05, 3.9620e-05], device='cuda:0')}, 140228500839016: {'step': 986, 'exp_avg': tensor([[[[ 4.9939e-04, -1.3309e-03,  1.2567e-03],\n",
      "          [-2.3688e-03, -9.0831e-04,  1.6614e-03],\n",
      "          [-1.2491e-03, -2.6361e-04, -1.1902e-03]],\n",
      "\n",
      "         [[-1.1430e-03,  1.8322e-04, -5.3562e-04],\n",
      "          [-2.0858e-03, -3.5245e-03, -1.7139e-03],\n",
      "          [-5.1339e-04, -2.1798e-04, -2.4087e-03]],\n",
      "\n",
      "         [[-1.2521e-03, -2.1088e-04, -2.4587e-03],\n",
      "          [-1.4289e-03, -2.1242e-03, -9.2462e-04],\n",
      "          [-1.0183e-03, -3.8584e-03, -1.2483e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1560e-03, -4.8578e-03, -8.3431e-04],\n",
      "          [-1.4337e-03, -2.0832e-03, -1.8880e-03],\n",
      "          [-4.2549e-03, -3.5560e-03, -3.7139e-05]],\n",
      "\n",
      "         [[ 2.9658e-03, -1.2193e-05,  2.7340e-03],\n",
      "          [ 3.9619e-03, -1.4692e-03,  5.0912e-04],\n",
      "          [ 8.1349e-04, -2.1236e-03, -2.1660e-03]],\n",
      "\n",
      "         [[-4.5983e-04, -1.8648e-03,  7.4851e-04],\n",
      "          [-8.9759e-05, -9.0547e-04, -1.4526e-03],\n",
      "          [ 1.7112e-04, -2.6840e-03, -2.4811e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9210e-04,  2.5526e-03, -1.0848e-03],\n",
      "          [ 1.0252e-03,  1.9913e-03, -9.6639e-06],\n",
      "          [-3.0756e-05,  6.2199e-04,  1.2048e-03]],\n",
      "\n",
      "         [[ 4.4201e-04,  1.3061e-04,  1.8683e-04],\n",
      "          [-1.3991e-03,  1.2412e-03, -2.0124e-04],\n",
      "          [ 8.9665e-04,  9.2905e-04,  5.1063e-04]],\n",
      "\n",
      "         [[ 1.7570e-03,  7.4627e-04,  1.4289e-03],\n",
      "          [ 1.1249e-04, -7.5623e-04, -2.4539e-03],\n",
      "          [ 1.1837e-03, -5.9961e-04, -1.0070e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1148e-03,  2.2384e-03,  4.9253e-04],\n",
      "          [ 1.6649e-03,  2.5602e-04, -3.4643e-04],\n",
      "          [ 1.3633e-03,  1.4128e-03, -8.4694e-05]],\n",
      "\n",
      "         [[ 9.2151e-04,  5.8784e-04, -8.8798e-04],\n",
      "          [-8.4925e-05,  2.5238e-03,  8.3983e-04],\n",
      "          [-1.3438e-03, -5.6115e-04, -1.7371e-04]],\n",
      "\n",
      "         [[-4.1399e-04,  1.2585e-04, -1.4361e-03],\n",
      "          [-5.4102e-04, -7.9141e-04,  3.2896e-04],\n",
      "          [ 7.9243e-04, -1.3551e-03, -4.2686e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.5727e-04,  3.1885e-04,  1.0862e-03],\n",
      "          [ 4.5214e-04,  9.0316e-04, -1.0131e-04],\n",
      "          [ 1.0528e-03,  1.5176e-03, -6.0403e-04]],\n",
      "\n",
      "         [[ 1.5408e-03,  1.7980e-03,  5.6929e-04],\n",
      "          [ 2.0831e-03,  2.1069e-03,  1.1020e-03],\n",
      "          [ 7.5069e-04,  1.8287e-03,  1.8280e-03]],\n",
      "\n",
      "         [[ 3.1340e-04,  9.6873e-04,  1.1105e-03],\n",
      "          [ 1.1495e-03,  3.6285e-04,  1.2652e-03],\n",
      "          [ 1.1199e-03,  2.7689e-04,  1.2001e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5091e-03,  4.0105e-05,  1.3207e-03],\n",
      "          [ 8.6416e-04,  1.4363e-03,  1.1806e-03],\n",
      "          [ 1.6995e-03, -4.7219e-04, -2.0485e-04]],\n",
      "\n",
      "         [[ 4.9024e-04,  1.0875e-03, -9.2106e-04],\n",
      "          [-6.4187e-04,  1.2240e-03, -4.5759e-04],\n",
      "          [ 8.1007e-04,  3.0033e-03,  3.3846e-04]],\n",
      "\n",
      "         [[-1.8649e-04, -1.8000e-06, -5.2395e-04],\n",
      "          [-6.2862e-04,  5.3837e-06, -1.2328e-03],\n",
      "          [-8.3866e-04, -9.4454e-04, -2.2807e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 9.8335e-04,  1.8174e-03,  4.8124e-05],\n",
      "          [ 1.4937e-03,  6.3282e-04, -1.8157e-05],\n",
      "          [ 2.1309e-03,  1.5132e-03,  1.0163e-03]],\n",
      "\n",
      "         [[ 3.6247e-04, -6.3930e-04,  5.3996e-04],\n",
      "          [ 9.4465e-04, -2.3885e-04,  5.4836e-04],\n",
      "          [ 1.0182e-03,  1.5811e-03,  2.1878e-04]],\n",
      "\n",
      "         [[-1.3525e-04, -3.0732e-05, -2.5570e-04],\n",
      "          [ 1.0326e-03,  7.1862e-04,  9.3650e-04],\n",
      "          [ 1.3519e-03,  9.7053e-04,  1.6149e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5890e-03,  1.9923e-03,  2.8468e-03],\n",
      "          [ 1.3408e-04,  5.1903e-04,  1.4286e-03],\n",
      "          [ 6.8318e-04,  1.7822e-03,  2.3935e-03]],\n",
      "\n",
      "         [[-4.7276e-04, -1.4215e-03, -1.9842e-03],\n",
      "          [ 7.2553e-04,  6.4639e-04,  8.4571e-04],\n",
      "          [ 1.3982e-03,  1.9239e-04, -1.2937e-04]],\n",
      "\n",
      "         [[-3.3908e-04, -1.0404e-03,  7.2570e-04],\n",
      "          [-8.7978e-05, -9.9656e-04, -3.8269e-04],\n",
      "          [ 1.1441e-04, -1.0709e-03, -4.0788e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6162e-03,  5.4900e-03,  4.8704e-03],\n",
      "          [ 1.5738e-03,  1.9590e-03,  2.3961e-03],\n",
      "          [ 8.7358e-04,  4.4640e-04,  1.7240e-03]],\n",
      "\n",
      "         [[ 3.1044e-03,  1.5235e-03,  3.6617e-03],\n",
      "          [ 3.6539e-03,  1.5992e-03,  4.9987e-04],\n",
      "          [ 7.0937e-04,  3.1171e-03,  2.6248e-03]],\n",
      "\n",
      "         [[ 3.0320e-03,  4.3486e-03,  1.8253e-03],\n",
      "          [ 3.4341e-03,  8.9228e-04,  1.5209e-03],\n",
      "          [ 1.5060e-03,  1.7247e-03,  2.0225e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6107e-03,  1.1451e-03,  1.3382e-03],\n",
      "          [ 1.3419e-03,  3.3491e-03,  2.5305e-03],\n",
      "          [ 2.9474e-03,  2.4176e-03,  3.0693e-03]],\n",
      "\n",
      "         [[ 3.8659e-04,  2.4776e-03,  3.1512e-03],\n",
      "          [-2.6576e-04,  2.7106e-03,  2.4712e-03],\n",
      "          [-1.1132e-04,  1.3072e-03,  8.2829e-04]],\n",
      "\n",
      "         [[-6.8307e-05, -1.0655e-03, -1.6566e-03],\n",
      "          [-8.8467e-04, -8.6257e-04, -7.3866e-04],\n",
      "          [-9.0340e-04, -1.7744e-03, -1.7689e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4760e-03, -1.8081e-03, -5.7552e-04],\n",
      "          [-2.9506e-03, -3.1562e-03, -1.1071e-03],\n",
      "          [-3.5590e-04, -5.2283e-04, -1.9750e-03]],\n",
      "\n",
      "         [[-2.2111e-03, -1.1284e-03, -1.7574e-03],\n",
      "          [-7.6142e-04,  6.9547e-04, -2.3162e-04],\n",
      "          [ 4.6439e-04,  5.0524e-04,  9.1413e-04]],\n",
      "\n",
      "         [[-1.4250e-03,  1.1766e-04,  1.6389e-04],\n",
      "          [-2.0819e-03, -6.3437e-04, -2.1349e-04],\n",
      "          [-4.2228e-04, -2.4365e-05,  1.7217e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.1903e-04,  1.2674e-03,  4.0220e-04],\n",
      "          [ 1.0735e-03, -4.6087e-04, -5.5232e-04],\n",
      "          [-1.4202e-03, -2.1579e-03, -3.4220e-03]],\n",
      "\n",
      "         [[ 3.6110e-04, -6.5285e-05, -1.8022e-04],\n",
      "          [-2.1739e-04, -3.2119e-04, -1.1447e-03],\n",
      "          [-1.6527e-03, -2.0774e-04, -3.0067e-04]],\n",
      "\n",
      "         [[ 1.9479e-03,  1.2886e-03,  8.9629e-04],\n",
      "          [ 2.8061e-04,  1.3808e-03,  4.5825e-04],\n",
      "          [ 2.6103e-05,  2.1596e-04, -5.8035e-04]]]], device='cuda:0'), 'exp_avg_sq': tensor([[[[4.7173e-05, 3.3466e-05, 4.0377e-05],\n",
      "          [3.8417e-05, 2.9156e-05, 3.2228e-05],\n",
      "          [3.3312e-05, 3.7422e-05, 3.6985e-05]],\n",
      "\n",
      "         [[4.2942e-05, 4.0823e-05, 3.9496e-05],\n",
      "          [3.2615e-05, 4.0943e-05, 3.7230e-05],\n",
      "          [3.6767e-05, 4.0797e-05, 2.8900e-05]],\n",
      "\n",
      "         [[2.8530e-05, 3.7111e-05, 3.1013e-05],\n",
      "          [3.4244e-05, 3.1436e-05, 2.9830e-05],\n",
      "          [3.5714e-05, 2.4899e-05, 3.1511e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.9517e-05, 3.2051e-05, 3.7770e-05],\n",
      "          [3.5422e-05, 4.0231e-05, 4.8056e-05],\n",
      "          [2.6486e-05, 4.2072e-05, 3.4424e-05]],\n",
      "\n",
      "         [[3.3940e-05, 2.5042e-05, 2.5144e-05],\n",
      "          [2.8742e-05, 3.6621e-05, 2.2373e-05],\n",
      "          [3.5132e-05, 3.9398e-05, 2.9984e-05]],\n",
      "\n",
      "         [[1.1942e-05, 1.3966e-05, 1.4812e-05],\n",
      "          [1.0986e-05, 1.2318e-05, 1.6978e-05],\n",
      "          [1.1956e-05, 1.3587e-05, 1.6566e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.7018e-05, 2.4987e-05, 2.7732e-05],\n",
      "          [3.4099e-05, 3.4509e-05, 2.9069e-05],\n",
      "          [2.5949e-05, 2.2863e-05, 2.5812e-05]],\n",
      "\n",
      "         [[2.8776e-05, 2.7942e-05, 2.8424e-05],\n",
      "          [2.5472e-05, 2.7517e-05, 3.1260e-05],\n",
      "          [2.4186e-05, 2.7142e-05, 2.6419e-05]],\n",
      "\n",
      "         [[2.2035e-05, 2.0795e-05, 2.2668e-05],\n",
      "          [2.3700e-05, 2.3445e-05, 2.5128e-05],\n",
      "          [1.6986e-05, 2.4082e-05, 1.8278e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.0438e-05, 2.8061e-05, 2.7872e-05],\n",
      "          [2.4325e-05, 1.8698e-05, 2.1679e-05],\n",
      "          [2.7117e-05, 3.1978e-05, 3.0880e-05]],\n",
      "\n",
      "         [[2.2835e-05, 1.9997e-05, 1.7600e-05],\n",
      "          [2.0213e-05, 2.1854e-05, 2.1537e-05],\n",
      "          [1.9511e-05, 1.9703e-05, 2.0572e-05]],\n",
      "\n",
      "         [[1.0228e-05, 8.2324e-06, 6.5908e-06],\n",
      "          [1.0347e-05, 9.2741e-06, 4.7774e-06],\n",
      "          [9.3925e-06, 9.0363e-06, 5.4443e-06]]],\n",
      "\n",
      "\n",
      "        [[[1.9745e-05, 2.6993e-05, 2.2819e-05],\n",
      "          [2.8574e-05, 2.7214e-05, 2.6873e-05],\n",
      "          [2.0996e-05, 3.0350e-05, 1.9137e-05]],\n",
      "\n",
      "         [[2.6232e-05, 2.3513e-05, 2.1155e-05],\n",
      "          [1.9635e-05, 2.4373e-05, 1.8581e-05],\n",
      "          [2.0693e-05, 2.0976e-05, 2.0828e-05]],\n",
      "\n",
      "         [[1.8496e-05, 1.5729e-05, 1.8608e-05],\n",
      "          [1.8062e-05, 2.5253e-05, 1.7369e-05],\n",
      "          [1.5783e-05, 1.8192e-05, 1.8982e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.5581e-05, 2.2952e-05, 1.8925e-05],\n",
      "          [2.5953e-05, 2.3086e-05, 2.2850e-05],\n",
      "          [2.5896e-05, 2.1638e-05, 2.0063e-05]],\n",
      "\n",
      "         [[1.8218e-05, 1.4801e-05, 1.6400e-05],\n",
      "          [2.2430e-05, 1.8966e-05, 2.2552e-05],\n",
      "          [1.7942e-05, 2.2101e-05, 1.6778e-05]],\n",
      "\n",
      "         [[7.0907e-06, 8.9913e-06, 8.1129e-06],\n",
      "          [6.7064e-06, 8.5488e-06, 7.8404e-06],\n",
      "          [7.7863e-06, 7.4459e-06, 8.9502e-06]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.6188e-05, 1.3443e-05, 1.4914e-05],\n",
      "          [1.8088e-05, 1.9638e-05, 1.5551e-05],\n",
      "          [1.4198e-05, 1.6135e-05, 1.8289e-05]],\n",
      "\n",
      "         [[1.4923e-05, 2.0602e-05, 2.0647e-05],\n",
      "          [1.7023e-05, 1.6923e-05, 1.5899e-05],\n",
      "          [1.7112e-05, 1.8759e-05, 1.4873e-05]],\n",
      "\n",
      "         [[1.3895e-05, 1.1755e-05, 1.2270e-05],\n",
      "          [1.6307e-05, 1.2474e-05, 1.6804e-05],\n",
      "          [1.2416e-05, 1.7178e-05, 1.5625e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.2288e-05, 1.8763e-05, 2.1124e-05],\n",
      "          [1.3324e-05, 1.5744e-05, 1.3575e-05],\n",
      "          [1.4496e-05, 1.5661e-05, 2.3340e-05]],\n",
      "\n",
      "         [[1.6852e-05, 1.3478e-05, 1.2799e-05],\n",
      "          [1.4703e-05, 1.3415e-05, 1.7323e-05],\n",
      "          [1.3365e-05, 1.2487e-05, 1.3030e-05]],\n",
      "\n",
      "         [[5.3239e-06, 6.6010e-06, 6.3653e-06],\n",
      "          [5.1375e-06, 5.6696e-06, 6.6255e-06],\n",
      "          [5.6987e-06, 5.8070e-06, 6.7479e-06]]],\n",
      "\n",
      "\n",
      "        [[[3.3551e-05, 3.5702e-05, 2.6530e-05],\n",
      "          [2.8275e-05, 3.0384e-05, 2.6110e-05],\n",
      "          [2.8305e-05, 3.1985e-05, 2.6388e-05]],\n",
      "\n",
      "         [[3.1581e-05, 2.8124e-05, 2.9595e-05],\n",
      "          [2.5572e-05, 3.0197e-05, 2.7500e-05],\n",
      "          [2.6508e-05, 3.1780e-05, 3.1017e-05]],\n",
      "\n",
      "         [[2.5129e-05, 2.7029e-05, 1.9848e-05],\n",
      "          [2.5449e-05, 2.4199e-05, 2.5094e-05],\n",
      "          [2.1317e-05, 2.6639e-05, 2.4435e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.8141e-05, 2.6263e-05, 2.5013e-05],\n",
      "          [2.4779e-05, 3.5414e-05, 2.7782e-05],\n",
      "          [2.9943e-05, 2.3885e-05, 2.9923e-05]],\n",
      "\n",
      "         [[2.0573e-05, 2.7293e-05, 2.9658e-05],\n",
      "          [2.5702e-05, 2.4892e-05, 2.2933e-05],\n",
      "          [2.4368e-05, 2.3646e-05, 2.6095e-05]],\n",
      "\n",
      "         [[1.2669e-05, 1.3530e-05, 1.6120e-05],\n",
      "          [1.2131e-05, 1.3395e-05, 1.5447e-05],\n",
      "          [1.0605e-05, 1.2513e-05, 1.4006e-05]]],\n",
      "\n",
      "\n",
      "        [[[3.0286e-05, 3.2892e-05, 3.0893e-05],\n",
      "          [3.1746e-05, 3.0340e-05, 2.9685e-05],\n",
      "          [3.0200e-05, 2.8732e-05, 2.7331e-05]],\n",
      "\n",
      "         [[2.3872e-05, 2.7117e-05, 2.8057e-05],\n",
      "          [3.2363e-05, 3.1722e-05, 3.4579e-05],\n",
      "          [2.5222e-05, 2.9479e-05, 2.5404e-05]],\n",
      "\n",
      "         [[2.2772e-05, 3.1655e-05, 2.2152e-05],\n",
      "          [2.5675e-05, 2.2026e-05, 2.7234e-05],\n",
      "          [2.6580e-05, 2.5452e-05, 3.0905e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.0680e-05, 2.5587e-05, 3.5389e-05],\n",
      "          [2.7486e-05, 3.9804e-05, 2.7083e-05],\n",
      "          [2.8471e-05, 2.9361e-05, 3.4657e-05]],\n",
      "\n",
      "         [[2.1637e-05, 2.4471e-05, 2.2763e-05],\n",
      "          [2.5794e-05, 2.7989e-05, 1.9262e-05],\n",
      "          [3.1857e-05, 2.9159e-05, 2.2112e-05]],\n",
      "\n",
      "         [[1.1336e-05, 1.0522e-05, 1.4223e-05],\n",
      "          [1.2001e-05, 1.1415e-05, 1.3906e-05],\n",
      "          [1.0899e-05, 1.1473e-05, 1.3555e-05]]]], device='cuda:0')}, 140228500838728: {'step': 986, 'exp_avg': tensor([-3.7761e-10, -9.9568e-10,  4.5493e-10, -1.2065e-11, -1.4958e-10,\n",
      "         4.2618e-11, -5.1795e-10, -1.3578e-10, -7.2897e-10, -9.4974e-11,\n",
      "         1.7831e-10, -9.5373e-10,  1.2335e-09,  5.0904e-10,  1.8225e-11,\n",
      "         1.1122e-09, -3.1614e-10, -7.5673e-10,  1.2813e-11, -1.7604e-10,\n",
      "         3.2425e-10, -8.8869e-10, -4.8107e-10, -6.8652e-10, -8.7691e-10,\n",
      "         1.9485e-11, -2.2265e-10, -3.2682e-10,  3.1326e-10, -3.8804e-10,\n",
      "        -3.9926e-10, -6.5428e-10, -1.1605e-09,  4.2435e-11,  2.4973e-10,\n",
      "         7.1527e-10, -6.9754e-10,  1.5108e-09, -1.8228e-10, -6.5921e-11,\n",
      "        -1.6073e-10, -5.8609e-10, -3.6404e-10,  1.6287e-10, -8.3675e-10,\n",
      "         2.1622e-10,  6.1508e-11, -4.6300e-10, -5.8004e-10, -6.6309e-10,\n",
      "         2.4105e-10, -1.0817e-10, -1.3489e-10,  9.4836e-11, -1.6338e-10,\n",
      "         5.9779e-11,  5.2147e-10,  5.7350e-10,  1.9084e-11, -1.9946e-11,\n",
      "         9.9872e-11,  4.0652e-10,  6.0649e-10, -8.2172e-10], device='cuda:0'), 'exp_avg_sq': tensor([6.0784e-18, 3.3779e-18, 4.0204e-18, 4.8236e-18, 1.5725e-18, 9.5277e-18,\n",
      "        3.9146e-18, 3.1263e-18, 3.6570e-18, 4.6370e-18, 1.9798e-18, 4.5462e-18,\n",
      "        6.2193e-18, 4.4317e-18, 5.4352e-18, 6.3394e-18, 4.2884e-18, 4.8407e-18,\n",
      "        2.4068e-18, 5.0776e-18, 3.1447e-18, 3.6258e-18, 3.2048e-18, 4.6766e-18,\n",
      "        2.3115e-18, 3.0545e-18, 2.0669e-18, 4.2186e-18, 2.7032e-18, 3.3207e-18,\n",
      "        2.8595e-18, 3.7430e-18, 2.8609e-18, 3.1577e-18, 3.9945e-18, 4.4839e-18,\n",
      "        3.9158e-18, 4.2207e-18, 3.0965e-18, 3.9140e-18, 2.3535e-18, 3.3126e-18,\n",
      "        4.2947e-18, 2.5733e-18, 4.4946e-18, 3.3927e-18, 3.4176e-18, 3.0978e-18,\n",
      "        3.9813e-18, 4.8881e-18, 5.0405e-18, 3.3726e-18, 4.9194e-18, 4.6488e-18,\n",
      "        4.7321e-18, 2.2010e-18, 4.6650e-18, 4.3356e-18, 4.2311e-18, 4.0700e-18,\n",
      "        2.4728e-18, 2.3764e-18, 4.9432e-18, 5.9075e-18], device='cuda:0')}, 140228500838872: {'step': 986, 'exp_avg': tensor([-1.2586e-03,  1.0885e-03,  1.5452e-03, -1.4326e-03, -2.3526e-03,\n",
      "        -1.4393e-03, -1.4336e-03,  1.1743e-04,  1.2200e-03, -1.1214e-04,\n",
      "         2.0559e-03,  1.5866e-03, -1.3142e-03,  1.6545e-03, -2.6041e-03,\n",
      "        -3.0273e-03, -1.6201e-03,  1.4251e-04, -1.4398e-03, -4.3444e-04,\n",
      "         2.9504e-04, -2.8766e-03,  1.9891e-03, -1.5672e-03,  2.8284e-03,\n",
      "        -4.4937e-03,  1.2008e-03, -2.8410e-03,  1.0131e-03,  6.6213e-03,\n",
      "        -3.1542e-04,  2.9628e-03,  4.9556e-04,  1.9456e-03, -9.3756e-05,\n",
      "        -1.2550e-04,  3.5447e-03, -4.9379e-04,  3.4221e-03, -1.3739e-03,\n",
      "         2.8395e-03,  2.2776e-03, -3.1354e-04, -3.2229e-03, -9.3854e-05,\n",
      "        -1.6379e-03,  2.3935e-03,  1.9188e-03, -2.8161e-03, -1.1544e-03,\n",
      "        -4.8186e-04, -1.3650e-03,  7.4829e-04, -2.2648e-03,  5.1341e-04,\n",
      "         7.0356e-04, -1.6480e-03,  2.5318e-03,  1.7545e-04,  1.1316e-04,\n",
      "         1.2891e-04,  9.7766e-04,  1.8687e-03, -2.4446e-03], device='cuda:0'), 'exp_avg_sq': tensor([4.8697e-05, 6.4394e-05, 2.6652e-05, 3.8921e-05, 4.6054e-05, 7.3367e-05,\n",
      "        4.2722e-05, 2.8390e-05, 3.6397e-05, 5.9329e-05, 5.6552e-05, 4.3047e-05,\n",
      "        4.6851e-05, 3.8694e-05, 5.4389e-05, 4.2094e-05, 3.5670e-05, 3.6192e-05,\n",
      "        2.8161e-05, 2.7414e-05, 4.7851e-05, 3.8867e-05, 3.1921e-05, 3.6007e-05,\n",
      "        3.4428e-05, 3.4231e-05, 6.3823e-05, 4.6616e-05, 3.4112e-05, 3.2981e-05,\n",
      "        4.2485e-05, 5.8329e-05, 4.5497e-05, 4.3971e-05, 2.7728e-05, 4.1562e-05,\n",
      "        4.7001e-05, 3.7164e-05, 4.5283e-05, 3.9715e-05, 4.3500e-05, 3.3038e-05,\n",
      "        4.1387e-05, 3.1247e-05, 4.1876e-05, 3.3323e-05, 4.2452e-05, 5.6962e-05,\n",
      "        3.0788e-05, 3.1888e-05, 4.5240e-05, 6.8336e-05, 5.0810e-05, 4.2225e-05,\n",
      "        3.1548e-05, 4.6353e-05, 4.7377e-05, 4.7583e-05, 4.6150e-05, 5.6712e-05,\n",
      "        3.5812e-05, 4.2908e-05, 3.4379e-05, 4.2038e-05], device='cuda:0')}, 140228500838800: {'step': 986, 'exp_avg': tensor([-3.0203e-04,  3.2673e-03,  3.3054e-03,  7.6946e-04, -6.2800e-04,\n",
      "         1.2536e-03, -9.0244e-04,  3.5469e-03,  4.4436e-03,  2.2895e-03,\n",
      "         6.4024e-04,  3.7854e-03, -2.8682e-04,  1.6521e-03, -1.3289e-04,\n",
      "        -1.0884e-03, -2.4617e-03, -5.9288e-05, -1.6474e-03, -8.4498e-04,\n",
      "         3.0495e-03, -4.0958e-04,  2.4100e-03,  1.4733e-04,  2.7058e-03,\n",
      "        -2.6855e-03,  2.9785e-03,  7.7046e-04,  3.7113e-04,  5.8888e-03,\n",
      "         2.2303e-04,  2.0491e-03,  1.0967e-03, -1.1561e-04,  1.2999e-03,\n",
      "         8.4168e-04,  4.1759e-03,  3.7063e-04,  2.6599e-03, -1.3693e-03,\n",
      "         1.0704e-03,  3.9452e-03, -3.0697e-04, -2.9225e-03,  1.3473e-03,\n",
      "         1.4162e-03,  1.7224e-03,  2.1974e-03,  8.6079e-05,  8.6153e-04,\n",
      "         3.3160e-04,  7.9461e-04,  9.1825e-04, -1.4870e-03,  7.4139e-04,\n",
      "         1.1679e-03, -1.9761e-03,  1.0609e-03, -6.2311e-04,  1.2727e-04,\n",
      "         1.7302e-03,  1.3826e-03, -1.4117e-03, -3.1712e-04], device='cuda:0'), 'exp_avg_sq': tensor([2.4253e-05, 2.3698e-05, 2.1460e-05, 2.3791e-05, 2.0110e-05, 3.5287e-05,\n",
      "        2.2930e-05, 2.2637e-05, 1.9758e-05, 3.0786e-05, 2.0608e-05, 2.4081e-05,\n",
      "        3.1615e-05, 2.5438e-05, 2.3853e-05, 2.4704e-05, 2.3830e-05, 2.3244e-05,\n",
      "        1.9368e-05, 1.9128e-05, 2.3580e-05, 2.3433e-05, 1.8937e-05, 2.3556e-05,\n",
      "        1.8498e-05, 2.3063e-05, 2.2491e-05, 3.0560e-05, 2.0842e-05, 2.0909e-05,\n",
      "        2.1911e-05, 2.5683e-05, 2.3664e-05, 2.0978e-05, 1.9943e-05, 2.1622e-05,\n",
      "        2.3044e-05, 1.9038e-05, 1.8197e-05, 2.4351e-05, 1.9948e-05, 2.5621e-05,\n",
      "        2.6812e-05, 2.1325e-05, 2.5951e-05, 2.2507e-05, 2.0635e-05, 2.6614e-05,\n",
      "        1.7720e-05, 2.3755e-05, 2.9231e-05, 2.7265e-05, 2.9110e-05, 2.2417e-05,\n",
      "        1.9977e-05, 1.9435e-05, 2.7360e-05, 2.2445e-05, 2.3902e-05, 2.9217e-05,\n",
      "        2.0887e-05, 1.8914e-05, 2.2660e-05, 2.2294e-05], device='cuda:0')}, 140228500837432: {'step': 986, 'exp_avg': tensor([[-1.2529e-05,  6.4439e-05,  9.5169e-06,  ...,  3.0733e-06,\n",
      "         -1.9258e-05,  1.0285e-04],\n",
      "        [-4.0177e-05, -3.1564e-05, -1.2211e-05,  ...,  4.2939e-05,\n",
      "          1.1122e-04,  4.4987e-05],\n",
      "        [-6.9545e-06,  1.6804e-04,  4.3044e-05,  ...,  3.5390e-06,\n",
      "         -4.9120e-07,  1.1487e-04],\n",
      "        ...,\n",
      "        [-8.2602e-07, -4.8374e-06, -3.4084e-07,  ...,  1.7805e-05,\n",
      "          2.1340e-05,  1.6051e-06],\n",
      "        [ 3.0242e-07,  5.2225e-06,  1.8907e-06,  ..., -5.6512e-07,\n",
      "         -6.1647e-06,  4.3234e-06],\n",
      "        [-1.1284e-05, -1.0325e-05, -2.7477e-06,  ...,  1.7686e-07,\n",
      "          1.4802e-05,  1.8117e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[1.6740e-08, 1.1285e-08, 5.8551e-08,  ..., 2.7832e-08, 3.2465e-08,\n",
      "         1.9528e-08],\n",
      "        [1.0745e-07, 9.0961e-08, 9.3660e-08,  ..., 2.1135e-07, 2.0435e-07,\n",
      "         3.8509e-07],\n",
      "        [1.2447e-08, 1.0883e-08, 9.1879e-09,  ..., 1.3020e-08, 1.8949e-08,\n",
      "         1.8522e-08],\n",
      "        ...,\n",
      "        [5.5195e-09, 2.9375e-09, 4.2677e-09,  ..., 1.3109e-08, 1.2538e-08,\n",
      "         1.1579e-08],\n",
      "        [5.9382e-10, 4.8370e-10, 8.9020e-10,  ..., 8.5176e-10, 1.2513e-09,\n",
      "         1.2024e-09],\n",
      "        [8.3289e-09, 7.8111e-09, 1.8407e-08,  ..., 2.2905e-08, 1.3394e-08,\n",
      "         2.0027e-08]], device='cuda:0')}, 140228500839520: {'step': 986, 'exp_avg': tensor([4.2006e-06, 1.0462e-08, 3.5904e-05,  ..., 1.4390e-06, 9.4817e-08,\n",
      "        3.3714e-12], device='cuda:0'), 'exp_avg_sq': tensor([1.7588e-09, 4.9157e-10, 9.9892e-10,  ..., 6.4769e-10, 2.1283e-11,\n",
      "        8.1337e-10], device='cuda:0')}, 140228500839304: {'step': 986, 'exp_avg': tensor([0.0116], device='cuda:0'), 'exp_avg_sq': tensor([0.0006], device='cuda:0')}, 140228500839448: {'step': 986, 'exp_avg': tensor([-8.7665e-05, -1.0683e-04,  5.4055e-04,  ..., -8.8376e-04,\n",
      "        -1.4587e-06,  2.2635e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.3198e-07, 5.9767e-07, 9.9285e-07,  ..., 2.4006e-06, 1.2694e-08,\n",
      "        4.0399e-08], device='cuda:0')}, 140228500839376: {'step': 986, 'exp_avg': tensor([ 1.7640e-04,  4.7085e-06,  3.3098e-04,  ...,  5.1494e-04,\n",
      "         1.4918e-05, -3.5524e-06], device='cuda:0'), 'exp_avg_sq': tensor([4.5752e-07, 1.2273e-06, 4.1874e-06,  ..., 9.4523e-06, 1.3874e-08,\n",
      "        9.4833e-08], device='cuda:0')}, 140228501647224: {'step': 986, 'exp_avg': tensor([[-0.0040,  0.0011,  0.0008,  ..., -0.0005, -0.0002,  0.0066],\n",
      "        [ 0.0026,  0.0018, -0.0015,  ...,  0.0011,  0.0003, -0.0072],\n",
      "        [ 0.0014, -0.0028,  0.0006,  ..., -0.0007, -0.0001,  0.0006]],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([[4.2204e-04, 6.1937e-04, 2.9310e-05,  ..., 5.6018e-06, 6.9888e-05,\n",
      "         5.2954e-04],\n",
      "        [4.0210e-04, 5.0990e-04, 2.3445e-05,  ..., 7.8515e-06, 7.5695e-05,\n",
      "         5.2610e-04],\n",
      "        [3.5415e-04, 4.7357e-04, 3.3443e-05,  ..., 4.1743e-06, 7.1462e-05,\n",
      "         3.6887e-04]], device='cuda:0')}, 140228501646504: {'step': 986, 'exp_avg': tensor([ 0.0062, -0.0060, -0.0002], device='cuda:0'), 'exp_avg_sq': tensor([0.0009, 0.0015, 0.0010], device='cuda:0')}}\n",
      "param_groups \t [{'lr': 1.0000000000000002e-07, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'initial_lr': 0.001, 'params': [140228500830392, 140228500829672, 140228500828232, 140228500828448, 140228500832120, 140228500828736, 140228500837792, 140228500839952, 140228500840168, 140228500840240, 140228500839880, 140228500840096, 140228500839016, 140228500838728, 140228500838872, 140228500838800, 140228500837432, 140228500839520, 140228500839304, 140228500839448, 140228500839376, 140228501647224, 140228501646504]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dicat:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 8: SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save(model, MODELPATH+'cnn_pretrained.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'epoch': num_epochs,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}\n",
    "torch.save(state, MODELPATH+'cnn_pretrained.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=7680, out_features=1024, bias=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout(p=0.1)\n",
       "    (5): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (base env)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
