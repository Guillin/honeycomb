{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/features/submission_mel_002.npy'\n",
    "MODELPATH = 'output/models/cnn_003.model'\n",
    "BATCHSIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: LOADING DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CattleSoundDataset(Dataset):\n",
    "    \"\"\" FreeSound dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.len = X.shape[0]\n",
    "        self.x_data = torch.from_numpy(X)\n",
    "        self.y_data = torch.from_numpy(y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x_data[index], self.y_data[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = np.load(DATAPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(submission.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission: (1551, 60, 35)\n"
     ]
    }
   ],
   "source": [
    "print('submission:', submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = pd.read_csv('data/raw/test_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dataset = CattleSoundDataset(submission, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: MAKING DATASET ITERABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_loader = torch.utils.data.DataLoader(dataset=submission_dataset, \n",
    "                                           batch_size= BATCHSIZE, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=(1,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=(1,1)),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=1, out_channels=32),\n",
    "            ConvBlock(in_channels=32, out_channels=64),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(7680, 1024),\n",
    "            nn.PReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #x = torch.mean(x, dim=3)\n",
    "        #x, _ = torch.max(x, dim=2)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(num_classes=3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load(MODELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=7680, out_features=1024, bias=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout(p=0.1)\n",
       "    (5): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = []\n",
    "for images, labels in submission_loader:\n",
    "    #######################\n",
    "    #  USE GPU FOR MODEL  #\n",
    "    #######################\n",
    "    if torch.cuda.is_available():\n",
    "        images = Variable(images.unsqueeze(1).cuda())\n",
    "    else:\n",
    "        images = Variable(images.unsqueeze(1))\n",
    "\n",
    "    # Forward pass only to get logits/output\n",
    "    outputs = model(images)\n",
    "    if len(submit):\n",
    "        submit = np.concatenate((submit, outputs.cpu().detach().numpy()), axis=0) \n",
    "    else:\n",
    "        submit = outputs.cpu().detach().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = np.argmax(submit,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.DataFrame({'file' : file_names.filename, 'prediction' : submit})\n",
    "ds.to_csv(\"output/submits/submit_004.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds['prediction'].hist()\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch (base env)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
