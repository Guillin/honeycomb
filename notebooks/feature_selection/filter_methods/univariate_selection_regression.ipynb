{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Methods - Univariate feature selection - Regression\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests (ANOVA). The methods based on F-test estimate the degree of linear dependency between two random variables. They assume a linear relationship between the feature and the target. These methods also assume that the variables follow a Gaussian distribution.\n",
    "\n",
    "These may not always be the case for the variables in your dataset, so if looking to implement these procedure, you will need to corroborate these assumptions."
   ]
  },
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectPercentile"
   ],
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### load dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# load dataset and features from previus method\n",
    "features = np.load('../features/featuresFromMIRegression.npy').tolist()\n",
    "data = pd.read_pickle('../../data/features/features.pkl').loc[:,features].sample(frac=0.35).fillna(-9999)\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### split train - test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit.\n",
    "\n",
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### calculate univariate statistical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# calculate the univariate statistical measure between\n",
    "# each of the variables and the target\n",
    "# similarly to chi2, the output is the array of f-scores\n",
    "# and an array of pvalues, which are the ones we will compare\n",
    "\n",
    "univariate = f_regression(X_train.fillna(0), y_train)\n",
    "univariate"
   ],
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# let's add the variable names and order it for clearer visualisation\n",
    "univariate = pd.Series(univariate[1])\n",
    "univariate.index = X_train.columns\n",
    "univariate.sort_values(ascending=False, inplace=True)"
   ],
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# and now let's plot the p values\n",
    "univariate.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n",
    "pass"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the lower the p_value, the most predictive the feature is in principle.  Features towards the left with pvalues above 0.05, which are candidates to be removed, as this means that the features do not statistically significantly discriminate the target.\n",
    "\n",
    "Further investigation is needed if we want to know the true nature of the relationship between feature and target.\n",
    "\n",
    "In big datasets it is not unusual that the pvalues of the different features are really small. This does not say as much about the relevance of the feature. Mostly it indicates that it is a big the dataset.\n"
   ]
  },
  {
   "source": [
    "### save features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# how many var would you like to keep from the previous ANOVA analysis \n",
    "NNUMVAR = 10\n",
    "\n",
    "sel_ = SelectPercentile(f_regression, percentile=NNUMVAR).fit(X_train.fillna(0), y_train)\n",
    "features_to_keep = X_train.columns[sel_.get_support()].tolist()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "np.save('../features/featuresFromUnivariateRegression.npy',features_to_keep)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('ds': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1f33512659712c6a6ac90d8f6217146f941852120cd4340b6d127417f394cbe5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}