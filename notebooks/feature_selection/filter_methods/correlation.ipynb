{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Filter Methods - Correlation "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "### load dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and features from previus method\n",
    "features = np.load('featuresFromBasicMethods.npy').tolist()\n",
    "data = pd.read_pickle('../../data/features/features.pkl').loc[:,features].sample(frac=0.35).fillna(-9999)\n",
    "\n",
    "ddata = dd.from_pandas(data, npartitions=8)\n",
    "\n",
    "ddata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess whether they are correlated with other features\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(ddata.select_dtypes(include=numerics).columns)\n",
    "ddata = ddata[numerical_vars]\n",
    "ddata.shape"
   ]
  },
  {
   "source": [
    "### Brute force approach"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the following function we can select highly correlated features\n",
    "# it will remove the first feature that is correlated with anything else\n",
    "# without any other insight.\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr().compute()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = correlation(ddata, 0.88)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat2keep = [c for c in ddata.columns if c not in corr_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dddata = ddata.drop(labels=list(corr_features),axis=1)"
   ]
  },
  {
   "source": [
    "### plot matrix correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise correlated features\n",
    "# I will build the correlation matrix, which examines the \n",
    "# correlation of all features (for all possible feature combinations)\n",
    "# and then visualise the correlation matrix using seaborn\n",
    "corr_matrix = dddata.corr().compute()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(11,11)\n",
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "source": [
    "### save features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../features/featuresFromCorrelation.npy',feat2keep)"
   ]
  },
  {
   "source": [
    "## Second approach\n",
    "\n",
    "The second approach looks to identify groups of highly correlated features. And then, we can make further investigation within these groups to decide which feature we keep and which one we remove."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddata = dd.from_pandas(data, npartitions=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess whether they are correlated with other features\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(ddata.select_dtypes(include=numerics).columns)\n",
    "ddata = ddata[numerical_vars]\n",
    "ddata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataframe with the correlation between features\n",
    "# remember that the absolute value of the correlation\n",
    "# coefficient is important and not the sign\n",
    "\n",
    "corrmat = dddata.corr().compute()\n",
    "corrmat = corrmat.abs().unstack() # absolute value of corr coef\n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.8]\n",
    "corrmat = corrmat[corrmat < 1]\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find groups of correlated features\n",
    "\n",
    "grouped_feature_ls = []\n",
    "correlated_groups = []\n",
    "\n",
    "for feature in corrmat.feature1.unique():\n",
    "    if feature not in grouped_feature_ls:\n",
    "\n",
    "        # find all features correlated to a single feature\n",
    "        correlated_block = corrmat[corrmat.feature1 == feature]\n",
    "        grouped_feature_ls = grouped_feature_ls + list(\n",
    "            correlated_block.feature2.unique()) + [feature]\n",
    "\n",
    "        # append the block of features to the list\n",
    "        correlated_groups.append(correlated_block)\n",
    "\n",
    "print('found {} correlated groups'.format(len(correlated_groups)))\n",
    "print('out of {} total features'.format(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can visualise each group. We see that some groups contain\n",
    "# only 2 correlated features, some other groups present several features \n",
    "# that are correlated among themselves.\n",
    "\n",
    "for group in correlated_groups:\n",
    "    print(group)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now investigate further features within one group.\n",
    "# let's for example select group 3\n",
    "\n",
    "group = correlated_groups[2]\n",
    "group"
   ]
  }
 ]
}